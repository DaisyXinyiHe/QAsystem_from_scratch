{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# A Simple transformer question and answer model needs:\n",
        "* Tokinizer (Here i am using BERT's way to tokenize beginning and end of sentences)\n",
        "* Transformer encoder\n",
        "* QA head (predict start and end position)\n",
        "* Training and inference logic\n",
        "\n"
      ],
      "metadata": {
        "id": "F64zJ7O3cbSn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Use self-built attention head"
      ],
      "metadata": {
        "id": "bLQxgKC9j5SV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "PTfvlb4ObTv1"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import math\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "config = {\n",
        "        \"vocab_size\": 45,\n",
        "        \"hidden_size\": 64,\n",
        "        \"max_position_embeddings\": 64,\n",
        "        \"num_attention_heads\": 4,\n",
        "        'intermediate_size':10,\n",
        "        'hidden_dropout_prob':0.01,\n",
        "        \"num_hidden_layers\": 12,\n",
        "        'mask':None\n",
        "    }"
      ],
      "metadata": {
        "id": "MBvVdTLxGQYw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Tokinizer\n",
        "\n",
        "class SimpleTokinizer:\n",
        "  def __init__(self):\n",
        "    self.vocab = {\"[PAD]\":0, \"[CLS]\":1, \"[SEP]\":2,\"[UNK]\":3}\n",
        "    self.reverse_vocab = {0:\"[PAD]\", 1:\"[CLS]\", 2:\"[SEP]\",3:\"[UNK]\"}\n",
        "    self.idx = 4\n",
        "\n",
        "  def build_vocab(self,texts):\n",
        "    for text in texts:\n",
        "      for word in text.lower().split():\n",
        "        if word not in self.vocab:\n",
        "          self.vocab[word] = self.idx\n",
        "          self.reverse_vocab[self.idx] = word\n",
        "          self.idx+=1\n",
        "  def encode(self, question, contaxt, max_len = 64):\n",
        "    ## for each QA, input takes format of [CLS] question tokens [SEP] context tokens [SEP]\n",
        "    tokens = [\"[CLS]\"]+question.lower().split()+[\"[SEP]\"]+contaxt.lower().split()+[\"[SEP]\"]\n",
        "    token_ids = [self.vocab.get(token, self.vocab[\"[UNK]\"]) for token in tokens]\n",
        "    token_type_ids = [1]*(len(question.split())+2)+[2]*(len(context.split())+1)\n",
        "    attention_mask = [1] * len(token_ids)\n",
        "    padding = [0]*(max_len - len(token_ids))\n",
        "    # print(token_type_ids)\n",
        "    return {\n",
        "        'input_ids':torch.tensor(token_ids + padding[:max_len - len(token_ids)]),\n",
        "        'attention_mask':torch.tensor(attention_mask+padding[:max_len - len(token_ids)]),\n",
        "        'token':tokens+['[PAD]']*len(padding),\n",
        "        'token_type_ids':torch.tensor(token_type_ids+padding[:max_len - len(token_ids)]),\n",
        "\n",
        "    }"
      ],
      "metadata": {
        "id": "AWoGbLg3cehF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Sample\n",
        "question = \"What is KNN?\"\n",
        "context = '''KNN, or k-Nearest Neighbors, is a supervised machine learning algorithm used for both classification and regression tasks. It classifies new data points by finding the \"k\" most similar data points (neighbors) in the training data and assigning the new data point to the majority class among those neighbors.'''\n"
      ],
      "metadata": {
        "id": "sM_MmMgWGd8-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Tokenizer\n",
        "tokenizer = SimpleTokinizer()\n",
        "tokenizer.build_vocab([question, context])\n",
        "# input_ids, attention_mask = tokenizer.encode(question, context)\n",
        "inputs = tokenizer.encode(question, context)"
      ],
      "metadata": {
        "id": "ZsVyzA_WGd8-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# inputs"
      ],
      "metadata": {
        "id": "lN_yR2g3TJMD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# input_ids = input_ids.unsqueeze(0)\n",
        "# attention_mask = attention_mask.unsqueeze(0)"
      ],
      "metadata": {
        "id": "hbgu9-c2J8zo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# config['mask'] = attention_mask"
      ],
      "metadata": {
        "id": "YYsPnOP2RGZn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# input_ids.shape, attention_mask.shape"
      ],
      "metadata": {
        "id": "SUcbVzSYKz-l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Atttention head\n",
        "\n",
        "def scaled_dot_product_attention(q,k,v, mask = None):\n",
        "  # print(q.shape,k.shape,v.shape)\n",
        "  dim_k = k.size(-1) ## embedding size\n",
        "  # print(dim_k)\n",
        "  # print(k.transpose(1,2).shape)\n",
        "  scores = torch.bmm(q,k.transpose(1,2)) / math.sqrt(dim_k)\n",
        "  if mask is not None:\n",
        "    scores = scores.masked_fill(mask==0, -float('inf'))\n",
        "  weights = F.softmax(scores, dim=1)\n",
        "  attention_outputs = torch.bmm(weights, v)\n",
        "  return attention_outputs\n",
        "\n",
        "\n",
        "class AttentionHead(nn.Module):\n",
        "  def __init__(self, embed_dim, head_dim, mask=None):\n",
        "    super().__init__()\n",
        "    self.q = nn.Linear(embed_dim, head_dim)\n",
        "    self.k = nn.Linear(embed_dim, head_dim)\n",
        "    self.v = nn.Linear(embed_dim, head_dim)\n",
        "    self.mask = mask\n",
        "\n",
        "  def forward(self,hidden_state):\n",
        "    attention_outputs = scaled_dot_product_attention(self.q(hidden_state),self.k(hidden_state),self.v(hidden_state), mask = self.mask)\n",
        "\n",
        "    return attention_outputs\n",
        "\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "  def __init__(self,config):\n",
        "    super().__init__()\n",
        "    embed_dim = config['hidden_size']\n",
        "    num_heads = config['num_attention_heads']\n",
        "    head_dim = embed_dim // num_heads\n",
        "    mask = config['mask']\n",
        "    self.heads = nn.ModuleList(\n",
        "        [AttentionHead(embed_dim, head_dim, mask) for _ in range(num_heads)]\n",
        "    )\n",
        "    self.output_linear = nn.Linear(embed_dim, embed_dim)\n",
        "\n",
        "  def forward(self,hidden_state):\n",
        "    # print(hidden_state.shape)\n",
        "    # for h in self.heads:\n",
        "    #   print(h(hidden_state)[0][0].shape)\n",
        "    # print(self.heads)\n",
        "    x = torch.cat([h(hidden_state) for h in self.heads], dim = -1)\n",
        "    x = self.output_linear(x)\n",
        "    return x\n",
        "\n"
      ],
      "metadata": {
        "id": "upj8B52_feAm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "AttentionHead(config['hidden_size'], config['num_attention_heads'], config['mask'])"
      ],
      "metadata": {
        "id": "JcksK0yqYRfR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "multihead_attn = MultiHeadAttention(config)\n",
        "token_emb = nn.Embedding(config['vocab_size'], config['hidden_size'])\n",
        "input_embeds = token_emb(inputs['input_ids'])\n",
        "input_embeds = input_embeds.unsqueeze(0)\n",
        "attn_output = multihead_attn(input_embeds)"
      ],
      "metadata": {
        "id": "dIL-noipHAsb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FeedForward(nn.Module):\n",
        "  def __init__(self, config):\n",
        "    super().__init__()\n",
        "    self.linear1 = nn.Linear(config['hidden_size'], config['intermediate_size'])\n",
        "    self.linear2 = nn.Linear(config['intermediate_size'], config['hidden_size'])\n",
        "    self.gelu = nn.GELU()\n",
        "    self.dropout = nn.Dropout(config['hidden_dropout_prob'])\n",
        "\n",
        "  def forward(self,x):\n",
        "    x = self.linear1(x)\n",
        "    x = self.gelu(x)\n",
        "    x = self.linear2(x)\n",
        "    x = self.dropout(x)\n",
        "    return x\n"
      ],
      "metadata": {
        "id": "jGqt0bAug0Vi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feed_forward = FeedForward(config)"
      ],
      "metadata": {
        "id": "DKwjjqd0PTjK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ff_outputs = feed_forward(attn_output)"
      ],
      "metadata": {
        "id": "_S64BQZvPVG7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ff_outputs.shape"
      ],
      "metadata": {
        "id": "rk4RkliVPWXN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerEncoderLayer(nn.Module):\n",
        "  def __init__(self,config):\n",
        "    super().__init__()\n",
        "    self.layer_norm1 = nn.LayerNorm(config['hidden_size'])\n",
        "    self.layer_norm2 = nn.LayerNorm(config['hidden_size'])\n",
        "    self.attention = MultiHeadAttention(config)\n",
        "    self.feedforward = FeedForward(config)\n",
        "  def forward(self, x):\n",
        "    hidden_state = self.layer_norm1(x)\n",
        "    atten_output =  self.attention(hidden_state)\n",
        "    x+=atten_output\n",
        "    x += self.feedforward(self.layer_norm2(x))\n",
        "    return x\n"
      ],
      "metadata": {
        "id": "6brH7YThmSMh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_layer = TransformerEncoderLayer(config)\n",
        "print(input_embeds.shape)\n",
        "encoder_layer(input_embeds).shape"
      ],
      "metadata": {
        "id": "E_9yHmzsPZ6d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Embeddings(nn.Module):\n",
        "  def __init__(self,config):\n",
        "    super().__init__()\n",
        "    self.token_embeddings = nn.Embedding(config['vocab_size'], config['hidden_size'])\n",
        "    self.position_embeddings = nn.Embedding(config['max_position_embeddings'], config['hidden_size'])\n",
        "    self.layer_norm = nn.LayerNorm(config['hidden_size'], eps = 1e-12)\n",
        "    self.dropout = nn.Dropout()\n",
        "\n",
        "  def forward(self, input_ids):\n",
        "    seq_length = input_ids.unsqueeze(0).size(1)\n",
        "    position_ids = torch.arange(seq_length, dtype = torch.long).unsqueeze(0)\n",
        "    # print(input_ids)\n",
        "    token_embeddings = self.token_embeddings(input_ids)\n",
        "    position_embeddings = self.position_embeddings(position_ids)\n",
        "    embeddings = token_embeddings+position_embeddings\n",
        "    embeddings = self.layer_norm(embeddings)\n",
        "    embeddings = self.dropout(embeddings)\n",
        "    return embeddings\n",
        "\n"
      ],
      "metadata": {
        "id": "VQ4V-vC92JPH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_layer = Embeddings(config)\n",
        "embedding_layer(inputs['input_ids'])#.size()"
      ],
      "metadata": {
        "id": "jriCgnyGbYBy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerEncoder(nn.Module):\n",
        "  def __init__(self, config):\n",
        "    super().__init__()\n",
        "    self.embeddings = Embeddings(config)\n",
        "    self.layers = nn.ModuleList(\n",
        "        [TransformerEncoderLayer(config) for _ in range(config['num_hidden_layers'])]\n",
        "    )\n",
        "  def forward(self,x):\n",
        "    x = self.embeddings(x)\n",
        "    for layer in self.layers:\n",
        "      # print(layer)\n",
        "      x = layer(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "oMlQ6Sq14Lyz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = TransformerEncoder(config)\n",
        "encoder(inputs['input_ids']).size()"
      ],
      "metadata": {
        "id": "fkKToZBH6dRx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Add a QA head\n",
        "class QA_Transformer(nn.Module):\n",
        "  def __init__(self, vocab_size, d_model = 64, max_len = 64, heads = 4):\n",
        "    super().__init__()\n",
        "    self.config = {\n",
        "        \"vocab_size\": vocab_size,\n",
        "        \"hidden_size\": d_model,\n",
        "        \"max_position_embeddings\": max_len,\n",
        "        \"num_attention_heads\": heads,\n",
        "        'intermediate_size':10,\n",
        "        'hidden_dropout_prob':0.01,\n",
        "        \"num_hidden_layers\": 12,\n",
        "        'mask':None\n",
        "    }\n",
        "    # self.embedding = nn.Embedding(self.config['vocab_size'], self.config['hidden_size'])\n",
        "    self.encoder = TransformerEncoder(self.config)\n",
        "    # self.position_embeddings = nn.Parameter(torch.randn(1, self.config['max_position_embeddings'], self.config['hidden_size']))\n",
        "    # self.position_embeddings = nn.Parameter(torch.randint(1, self.config['max_position_embeddings'], self.config['hidden_size']))\n",
        "    self.qa_outputs = nn.Linear(self.config['hidden_size'], 2)\n",
        "\n",
        "  def forward(self, input_ids):#, attention_mask):\n",
        "    input_ids = input_ids.unsqueeze(0)\n",
        "    # attention_mask = attention_mask.unsqueeze(0)\n",
        "    # x = self.embedding(input_ids)+self.position_embeddings[:,:input_ids.size(1)]#.long()\n",
        "    x = self.encoder(input_ids)#, attention_mask)\n",
        "    logits = self.qa_outputs(x)\n",
        "    start_logits, end_logits = logits.split(1,dim=-1)\n",
        "    return start_logits.squeeze(-1), end_logits.squeeze(-1)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "MpKwDhBJ4nnF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Sample\n",
        "question = \"What is KNN?\"\n",
        "context = '''KNN, or k-Nearest Neighbors, is a supervised machine learning algorithm used for both classification and regression tasks. It classifies new data points by finding the \"k\" most similar data points (neighbors) in the training data and assigning the new data point to the majority class among those neighbors.'''\n"
      ],
      "metadata": {
        "id": "Lo3ZcEw56mP1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Tokenizer\n",
        "tokenizer = SimpleTokinizer()\n",
        "tokenizer.build_vocab([question, context])\n",
        "# input_ids, attention_mask = tokenizer.encode(question, context)\n",
        "# input_ids = input_ids.unsqueeze(0)\n",
        "# attention_mask = attention_mask.unsqueeze(0)\n",
        "input = tokenizer.encode(question, context)"
      ],
      "metadata": {
        "id": "D3ItMBvZ7RY_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# input['input_ids']"
      ],
      "metadata": {
        "id": "CTa0zsmO7oOt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input['attention_mask'].shape, input['input_ids'].shape, len(tokenizer.vocab)"
      ],
      "metadata": {
        "id": "D_uBD0-07qi7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input['input_ids'].shape"
      ],
      "metadata": {
        "id": "XonPcqt9e5z6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Model\n",
        "model = QA_Transformer(vocab_size =len(tokenizer.vocab), d_model = 64, max_len = 64, heads = 4)\n",
        "# start_logits, end_logits = model(input_ids.unsqueeze(0), attention_mask.unsqueeze(0))\n",
        "start_logits, end_logits = model(input['input_ids'])#, input['attention_mask'])"
      ],
      "metadata": {
        "id": "iVqu2XY370pb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# start_logits, end_logits"
      ],
      "metadata": {
        "id": "v205VN5Ok9tB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get answer span\n",
        "start_idx = torch.argmax(start_logits, dim=1).item()\n",
        "end_idx = torch.argmax(end_logits, dim=1).item()\n",
        "print(start_idx, end_idx)\n",
        "tokens = inputs['input_ids'].tolist()\n",
        "# print(tokens)\n",
        "answer = [tokenizer.reverse_vocab.get(t, '[UNK]') for t in tokens[start_idx:end_idx+1]]\n",
        "print(\"Predicted answer:\", \" \".join(answer))"
      ],
      "metadata": {
        "id": "dqyflOz6lC6e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model has not been trained yet and no seed is set so output is very unstable\n",
        "\n",
        "### Output from the above:\n",
        "46 58\n",
        "Predicted answer: to the majority class among those neighbors. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
        "\n",
        "### But sometimes it could be empty."
      ],
      "metadata": {
        "id": "k5IvGBMglWoX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Existing attention head from pytorch"
      ],
      "metadata": {
        "id": "oyHHQQOQjz-Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleTokenizer:\n",
        "    def __init__(self):\n",
        "        self.vocab = {\"[PAD]\": 0, \"[CLS]\": 1, \"[SEP]\": 2, \"[UNK]\": 3}\n",
        "        self.reverse_vocab = {0: \"[PAD]\", 1: \"[CLS]\", 2: \"[SEP]\", 3: \"[UNK]\"}\n",
        "        self.idx = 4\n",
        "\n",
        "    def build_vocab(self, texts):\n",
        "        for text in texts:\n",
        "            for word in text.lower().split():\n",
        "                if word not in self.vocab:\n",
        "                    self.vocab[word] = self.idx\n",
        "                    self.reverse_vocab[self.idx] = word\n",
        "                    self.idx += 1\n",
        "\n",
        "    def encode(self, question, context, max_len=64):\n",
        "        tokens = [\"[CLS]\"] + question.lower().split() + [\"[SEP]\"] + context.lower().split() + [\"[SEP]\"]\n",
        "        token_ids = [self.vocab.get(token, self.vocab[\"[UNK]\"]) for token in tokens]\n",
        "        attention_mask = [1] * len(token_ids)\n",
        "        padding = [0] * (max_len - len(token_ids))\n",
        "        return (\n",
        "            torch.tensor(token_ids + padding[:max_len - len(token_ids)]),\n",
        "            torch.tensor(attention_mask + padding[:max_len - len(token_ids)])\n",
        "        )\n"
      ],
      "metadata": {
        "id": "FL2SroxwguIm"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self, dim, heads):\n",
        "        super().__init__()\n",
        "        self.attn = nn.MultiheadAttention(embed_dim=dim, num_heads=heads, batch_first=True)\n",
        "        self.norm1 = nn.LayerNorm(dim)\n",
        "        self.ff = nn.Sequential(\n",
        "            nn.Linear(dim, dim * 4),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(dim * 4, dim)\n",
        "        )\n",
        "        self.norm2 = nn.LayerNorm(dim)\n",
        "\n",
        "    def forward(self, x, mask):\n",
        "        # print(x)\n",
        "        attn_output, _ = self.attn(x, x, x, key_padding_mask=~mask.bool())\n",
        "        # print(attn_output)\n",
        "        x = self.norm1(x + attn_output)\n",
        "        ff_output = self.ff(x)\n",
        "        x = self.norm2(x + ff_output)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "VFCJLB62-df4"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class QA_Transformer(nn.Module):\n",
        "    def __init__(self, vocab_size, d_model=64, max_len=64, heads=4):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
        "        self.pos_embedding = nn.Parameter(torch.randn(1, max_len, d_model))\n",
        "        self.encoder = TransformerBlock(d_model, heads)\n",
        "        self.qa_outputs = nn.Linear(d_model, 2)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        x = self.embedding(input_ids) + self.pos_embedding[:, :input_ids.size(1)]\n",
        "        # print(x.shape)\n",
        "        x = self.encoder(x, attention_mask)\n",
        "        # print(x.shape)\n",
        "        logits = self.qa_outputs(x)  # [batch, seq_len, 2]\n",
        "        start_logits, end_logits = logits.split(1, dim=-1)\n",
        "        return start_logits.squeeze(-1), end_logits.squeeze(-1), x\n"
      ],
      "metadata": {
        "id": "lTtXqNwigl-7"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample data\n",
        "question = \"What is KNN?\"\n",
        "context = '''KNN, or k-Nearest Neighbors, is a supervised machine learning algorithm used for both classification and regression tasks. It classifies new data points by finding the \"k\" most similar data points (neighbors) in the training data and assigning the new data point to the majority class among those neighbors.'''\n",
        "\n",
        "\n",
        "# Tokenizer\n",
        "tokenizer = SimpleTokenizer()\n",
        "tokenizer.build_vocab([question, context])\n",
        "input_ids, attention_mask = tokenizer.encode(question, context)\n",
        "\n",
        "# Model\n",
        "model = QA_Transformer(vocab_size=len(tokenizer.vocab))\n",
        "start_logits, end_logits,x = model(input_ids.unsqueeze(0), attention_mask.unsqueeze(0))\n",
        "\n",
        "# Get answer span\n",
        "start_idx = torch.argmax(start_logits, dim=1).item()\n",
        "end_idx = torch.argmax(end_logits, dim=1).item()\n",
        "tokens = input_ids.tolist()\n",
        "answer = [tokenizer.reverse_vocab.get(t, '[UNK]') for t in tokens[start_idx:end_idx+1]]\n",
        "print(\"Predicted answer:\", \" \".join(answer))\n"
      ],
      "metadata": {
        "id": "aQWToSpdgndv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "904b8bda-8d05-4d31-bdb8-beaa401f8936"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted answer: finding the \"k\" most similar data points (neighbors) in the training data and assigning the new data point to\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# x"
      ],
      "metadata": {
        "id": "P08qZCBsgo5O"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tokens[start_idx:end_idx+1]"
      ],
      "metadata": {
        "id": "RGac9X73gzOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model has not been trained yet and no seed is set so output is very unstable\n",
        "\n",
        "### output from above:\n",
        "Predicted answer: is a supervised machine learning algorithm used for both classification and regression tasks. it classifies new data points\n",
        "\n",
        "### But another run will be different\n",
        "### Model needs to be trained and set seeds"
      ],
      "metadata": {
        "id": "Vh_5Dw3ilckK"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lfvHyPD4hhLO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train model with SQuAD data"
      ],
      "metadata": {
        "id": "p2G6AEDSwZov"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)"
      ],
      "metadata": {
        "id": "6w2O6C6cKmue",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4226ea5f-b8af-4365-c053-0263fea3dd9e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7d6f30347d30>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "id": "23G6byOMwcEL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f2ea574-7c10-4048-9420-290bd101c868"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets) (3.19.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.12/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.34.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from datasets) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.12.15)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.14.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets) (1.1.7)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (2025.8.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "## Load SQuAD data\n",
        "squad = load_dataset('squad')"
      ],
      "metadata": {
        "id": "igidq2_zwdeX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02300f1b-2338-4dd4-8b25-7d489f110aa5"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# squad"
      ],
      "metadata": {
        "id": "6GmNewbmw_Ql"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = squad['train']\n",
        "val_data =squad['validation']"
      ],
      "metadata": {
        "id": "b381jPT9wtT5"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train_data"
      ],
      "metadata": {
        "id": "1H8kiG4lw8fs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# val_data"
      ],
      "metadata": {
        "id": "32p85c-3w9oy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train_data[200]"
      ],
      "metadata": {
        "id": "vTwR2d_owzFD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# val_data[100]['question']"
      ],
      "metadata": {
        "id": "zC33AYdUw1Nq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def char_to_token_span(context, answer_start, answer_text, tokenizer):\n",
        "  words = context.lower().split()\n",
        "  char_idx = 0\n",
        "  token_start = token_end = -1\n",
        "  for i, word in enumerate(words):\n",
        "    if context.lower().find(answer_text.lower(), char_idx) != -1:\n",
        "      char_idx = context.lower().find(answer_text.lower(),char_idx)\n",
        "      token_start = len(context[:char_idx].split())\n",
        "      token_end = token_start+len(answer_text.split()) - 1\n",
        "      break\n",
        "  return token_start, token_end"
      ],
      "metadata": {
        "id": "XDP-Qbo_xEvU"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build vocab from all texts in train + validation\n",
        "tokenizer = SimpleTokenizer()\n",
        "all_texts = []\n",
        "for item in train_data:\n",
        "    all_texts.extend([item[\"question\"], item[\"context\"]])\n",
        "tokenizer.build_vocab(all_texts)\n",
        "\n",
        "for item in val_data:\n",
        "    all_texts.extend([item[\"question\"], item[\"context\"]])\n",
        "tokenizer.build_vocab(all_texts)"
      ],
      "metadata": {
        "id": "YTnmpFfVyWC6"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class QADataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, data, tokenizer, max_len=64, doc_stride = 32):\n",
        "        self.data = data\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "        self.samples = []\n",
        "        self.doc_stride = doc_stride\n",
        "\n",
        "        for item in data:\n",
        "            q = item[\"question\"]\n",
        "            c = item[\"context\"]\n",
        "            a = item[\"answers\"][\"text\"][0]\n",
        "            a_start = item[\"answers\"][\"answer_start\"][0]\n",
        "            self.tokenizer.build_vocab([q, c])\n",
        "            input_ids, attn_mask = tokenizer.encode(q, c, max_len)\n",
        "            start, end = char_to_token_span(c, a_start, a, tokenizer)\n",
        "\n",
        "            # Adjust for [CLS] and question tokens\n",
        "            offset = 1 + len(q.split()) + 1\n",
        "            start += offset\n",
        "            end += offset\n",
        "            # print(end, max_len)\n",
        "            if end < max_len:\n",
        "              # print('end<max_len')\n",
        "              self.samples.append((input_ids, attn_mask, start, end))\n",
        "\n",
        "            else:\n",
        "\n",
        "              q_tokens = q.split()\n",
        "              c_tokens = c.split()\n",
        "\n",
        "              ## Sliding window over the context to deal with long context\n",
        "              doc_start = 0\n",
        "              # print(q,c,a)\n",
        "              while doc_start < len(c_tokens):\n",
        "\n",
        "                doc_end = min(doc_start+(max_len - len(q_tokens) - 3), len(c_tokens))\n",
        "                # (max_len - len(q_tokens) - 3) because we need to add question tokens and [cls] [sep] [sep] into the total doc feeding into the model.\n",
        "                # Format input will be like this: [cls] question tokens [sep] context tokens [sep]\n",
        "                # print(doc_start, doc_end,len(c_tokens))\n",
        "                # print(c_tokens[doc_start:doc_end])\n",
        "                # Check if the answer is inside this chunk\n",
        "                if start >= doc_start and end <= doc_end:\n",
        "                  # Adjust answer positions relative to this chunk because now it changes\n",
        "                  adj_start = start - doc_start\n",
        "                  adj_end = end - doc_start\n",
        "\n",
        "                  ## input\n",
        "                  new_context = ' '.join(c_tokens[doc_start:doc_end])\n",
        "                  self.tokenizer.build_vocab([q, new_context])\n",
        "                  input_ids, attn_mask = tokenizer.encode(q, new_context, max_len)\n",
        "                  offset = 1+len(q_tokens)+1\n",
        "                  start_pos = adj_start+offset\n",
        "                  end_pos = adj_end+offset\n",
        "                  # print(start_pos, end_pos)\n",
        "                  self.samples.append((input_ids, attn_mask, start_pos, end_pos))\n",
        "\n",
        "                if doc_end == len(c_tokens):\n",
        "                  break\n",
        "\n",
        "                doc_start+= self.doc_stride\n",
        "\n",
        "        # print(self.samples)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def __len__(self): return len(self.samples)\n",
        "    def __getitem__(self, idx):\n",
        "        input_ids, mask, start, end = self.samples[idx]\n",
        "        input_ids = F.pad(input_ids, (0, self.max_len - input_ids.shape[0]), value=0)\n",
        "        mask = F.pad(mask, (0, self.max_len - mask.shape[0]), value=0)\n",
        "        return {\n",
        "            \"input_ids\": input_ids,\n",
        "            \"attention_mask\": mask,\n",
        "            \"start_pos\": torch.tensor(start),\n",
        "            \"end_pos\": torch.tensor(end)\n",
        "        }\n"
      ],
      "metadata": {
        "id": "LR8E39nx0VkG"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_dataset = QADataset(train_data.select(range(2000)), tokenizer)  # Use a small subset\n"
      ],
      "metadata": {
        "id": "7H56DW2Sd4ST"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train_data[2]"
      ],
      "metadata": {
        "id": "5BozEbqn3au3"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(tokenizer.vocab)"
      ],
      "metadata": {
        "id": "1cO2qId6pmpX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c2088be-4cd3-4312-f11e-19240937edc4"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "206289"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset.__len__()"
      ],
      "metadata": {
        "id": "p3LR_zlhzLLt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce134a61-81c4-4b80-8e0f-8341b81ddffe"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2253"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "# device"
      ],
      "metadata": {
        "id": "Ci8L92BorvMk"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# torch.cuda.is_available()"
      ],
      "metadata": {
        "id": "RXohBNb-sX0q"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs=42\n",
        "# epochs = 3\n",
        "batch_size=16\n",
        "lr=5e-4"
      ],
      "metadata": {
        "id": "6enFNB3PsyVp"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = QA_Transformer(vocab_size=len(tokenizer.vocab))\n"
      ],
      "metadata": {
        "id": "P7Scgbfystk4"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train Model\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# initial_weights = model.embedding.weight.clone().detach() # Store initial weights\n",
        "\n",
        "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "dataset = train_dataset\n",
        "dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "# model.to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "# model.to(device) # Move model to device first\n",
        "model.train()\n",
        "\n",
        "loss_hist = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    total_loss = 0\n",
        "    for batch in dataloader:\n",
        "        input_ids = batch[\"input_ids\"]\n",
        "        mask = batch[\"attention_mask\"]\n",
        "        start_pos = batch[\"start_pos\"]\n",
        "        end_pos = batch[\"end_pos\"]\n",
        "\n",
        "        start_logits, end_logits,_ = model(input_ids, mask)\n",
        "        loss = loss_fn(start_logits, start_pos) + loss_fn(end_logits, end_pos)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}: Loss = {total_loss / len(dataloader):.4f}\")\n",
        "    loss_hist.append(total_loss / len(dataloader))\n"
      ],
      "metadata": {
        "id": "B-E5dJf-4-cw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6cee28b0-d52d-4ffb-c67d-7ec27eb2e51b"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Loss = 8.2756\n",
            "Epoch 2: Loss = 7.9360\n",
            "Epoch 3: Loss = 7.6816\n",
            "Epoch 4: Loss = 7.3043\n",
            "Epoch 5: Loss = 6.7247\n",
            "Epoch 6: Loss = 6.0024\n",
            "Epoch 7: Loss = 5.3292\n",
            "Epoch 8: Loss = 4.6422\n",
            "Epoch 9: Loss = 4.0289\n",
            "Epoch 10: Loss = 3.4528\n",
            "Epoch 11: Loss = 2.9375\n",
            "Epoch 12: Loss = 2.4892\n",
            "Epoch 13: Loss = 2.1058\n",
            "Epoch 14: Loss = 1.7709\n",
            "Epoch 15: Loss = 1.4512\n",
            "Epoch 16: Loss = 1.2225\n",
            "Epoch 17: Loss = 1.0146\n",
            "Epoch 18: Loss = 0.8470\n",
            "Epoch 19: Loss = 0.7396\n",
            "Epoch 20: Loss = 0.5747\n",
            "Epoch 21: Loss = 0.5376\n",
            "Epoch 22: Loss = 0.4471\n",
            "Epoch 23: Loss = 0.4052\n",
            "Epoch 24: Loss = 0.3255\n",
            "Epoch 25: Loss = 0.3003\n",
            "Epoch 26: Loss = 0.2772\n",
            "Epoch 27: Loss = 0.2566\n",
            "Epoch 28: Loss = 0.2317\n",
            "Epoch 29: Loss = 0.2053\n",
            "Epoch 30: Loss = 0.1971\n",
            "Epoch 31: Loss = 0.1789\n",
            "Epoch 32: Loss = 0.1431\n",
            "Epoch 33: Loss = 0.1513\n",
            "Epoch 34: Loss = 0.1649\n",
            "Epoch 35: Loss = 0.1814\n",
            "Epoch 36: Loss = 0.1540\n",
            "Epoch 37: Loss = 0.1603\n",
            "Epoch 38: Loss = 0.1415\n",
            "Epoch 39: Loss = 0.1650\n",
            "Epoch 40: Loss = 0.1660\n",
            "Epoch 41: Loss = 0.1213\n",
            "Epoch 42: Loss = 0.1297\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# updated_weights = model.embedding.weight.clone().detach()"
      ],
      "metadata": {
        "id": "2j_SbGqGP4eT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# initial_weights"
      ],
      "metadata": {
        "id": "dyjsG4pIQCi0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# updated_weights"
      ],
      "metadata": {
        "id": "E_fODqGDQCk-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(loss_hist)"
      ],
      "metadata": {
        "id": "iBtFTNOUQ-kA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "outputId": "a07b5067-077c-4031-e5f2-d1cd4718c503"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7d6e0b0eb6b0>]"
            ]
          },
          "metadata": {},
          "execution_count": 40
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# updated_weights = model.embedding.weight.clone().detach()"
      ],
      "metadata": {
        "id": "2e4TxGIZI_JJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# initial_weights"
      ],
      "metadata": {
        "id": "lRA5mf65JO9l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# updated_weights"
      ],
      "metadata": {
        "id": "ylBUqnc-JYs1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_answer(model, tokenizer, input_ids, attention_mask):\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    start_logits, end_logits,_ = model(input_ids.unsqueeze(0), attention_mask.unsqueeze(0))\n",
        "    start = torch.argmax(start_logits, dim=1).item()\n",
        "    end = torch.argmax(end_logits, dim=1).item()\n",
        "\n",
        "    max_len = input_ids.size(0)\n",
        "    if start>end:\n",
        "      return \"\"\n",
        "    tokens = input_ids[start:end+1].tolist()\n",
        "    words = [tokenizer.reverse_vocab.get(t,'[UNK]') for t in tokens]\n",
        "    return \" \".join(words)\n"
      ],
      "metadata": {
        "id": "qg3TFTR8LIpn"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Since we train with sliding window data, we should add sliding window inference\n",
        "def sliding_window_inference(question, context, tokenizer, model, max_len = 64, stride = 32):\n",
        "  input_ids, attention_mask = tokenizer.encode(question, context, max_len)\n",
        "  q_tokens = question.split()\n",
        "  c_tokens = context.split()\n",
        "  q_len = len(q_tokens)\n",
        "  c_len = len(c_tokens)\n",
        "  max_context_len = max_len - q_len - 3\n",
        "  result = []\n",
        "  doc_start = 0\n",
        "  while doc_start < c_len:\n",
        "    doc_end = min(doc_start+max_context_len, c_len)\n",
        "    new_context = ' '.join(c_tokens[doc_start:doc_end])\n",
        "    input_ids, attention_mask = tokenizer.encode(question, new_context, max_len)\n",
        "    pad_len = max_len - len(input_ids)\n",
        "    input_ids = F.pad(input_ids, (0, pad_len), value=0)\n",
        "    attention_mask = F.pad(attention_mask, (0, pad_len), value=0)\n",
        "    # input_ids = input_ids.unsqueeze(0)\n",
        "    # attention_mask = attention_mask.unsqueeze(0)\n",
        "    outputs = predict_answer(model, tokenizer, input_ids, attention_mask)\n",
        "    result.append(outputs)\n",
        "    doc_start += stride\n",
        "  return result\n",
        "\n"
      ],
      "metadata": {
        "id": "HVDLGl6AJYMt"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "def normalize(text):\n",
        "  def remove_punc(s):\n",
        "    return \"\".join(c for c in s if c not in string.punctuation)\n",
        "\n",
        "  def remove_articles(s):\n",
        "    return \" \".join([w for w in s.split() if w not in [\"a\",'an','the']])\n",
        "  return remove_articles(remove_punc(text.lower())).strip()\n",
        "\n"
      ],
      "metadata": {
        "id": "k01l2IsjRpzT"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_f1(pred, truth):\n",
        "  pred_tokens = normalize(pred).split()\n",
        "  truth_tokens = normalize(truth).split()\n",
        "  common = set(pred_tokens) & set(truth_tokens)\n",
        "  if len(common) == 0: return 0\n",
        "  precision = len(common) / len(pred_tokens)\n",
        "  recall = len(common) / len(truth_tokens)\n",
        "  return 2*(precision*recall) / (precision+recall)"
      ],
      "metadata": {
        "id": "8qYjajn4Synv"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_em(pred,truth):\n",
        "  return int(normalize(pred) == normalize(truth))"
      ],
      "metadata": {
        "id": "jt6vHiLGVnwt"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, dataset, tokenizer, num_samples=100):\n",
        "  em_scores = []\n",
        "  f1_scores = []\n",
        "  for i in range(num_samples):\n",
        "    sample = dataset.data[i]\n",
        "    question = sample['question']\n",
        "    context = sample['context']\n",
        "    gt_answer = sample['answers']['text'][0]\n",
        "    input_ids, attention_mask = tokenizer.encode(question, context, max_len = 64)\n",
        "    # input_ids = input_ids[:64]\n",
        "    # attention_mask = attention_mask[:64]\n",
        "    # pred_answer = predict_answer(model, tokenizer, input_ids, attention_mask)\n",
        "    pred_answer = sliding_window_inference(question, context, tokenizer, model, max_len = 64, stride = 32)\n",
        "    pred_answer = ' '.join(pred_answer)\n",
        "\n",
        "    em_scores.append(compute_em(pred_answer, gt_answer))\n",
        "    f1_scores.append(compute_f1(pred_answer, gt_answer))\n",
        "\n",
        "  avg_em = sum(em_scores) / len(em_scores)\n",
        "  avg_f1 = sum(f1_scores) / len(f1_scores)\n",
        "\n",
        "  print(f\"evaluate on {str(num_samples)} \\n\")\n",
        "  print(f'exact match: {avg_em:.2%}')\n",
        "  print(f'f1 score: {avg_f1:.2%}')\n",
        "  return avg_em, avg_f1"
      ],
      "metadata": {
        "id": "XVdMXz4sW2Bv"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Val dataset has tokens that are not included in training dataset, hence causing errors\n",
        "## Might need to train data with both val and train\n",
        "## Or lemmentization or or better tokenization methods\n",
        "\n",
        "\n",
        "train_subset = train_data.select(range(1000))\n",
        "train_dataset = QADataset(train_subset, tokenizer)\n",
        "evaluate(model, train_dataset, tokenizer,100)"
      ],
      "metadata": {
        "id": "pYTq36DsYNPI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1989bed9-32fb-43e4-fdd6-c4581ac20873"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "evaluate on 100 \n",
            "\n",
            "exact match: 4.00%\n",
            "f1 score: 21.43%\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.04, 0.2143417426105512)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_subset[0]"
      ],
      "metadata": {
        "id": "VdKsdGfQRZM7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4e4a24c-f74d-4b78-c8b3-8db336a6de70"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'id': '5733be284776f41900661182',\n",
              " 'title': 'University_of_Notre_Dame',\n",
              " 'context': 'Architecturally, the school has a Catholic character. Atop the Main Building\\'s gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.',\n",
              " 'question': 'To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?',\n",
              " 'answers': {'text': ['Saint Bernadette Soubirous'], 'answer_start': [515]}}"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sliding_window_inference(train_subset[0]['question'], train_subset[0]['context'], tokenizer, model, max_len = 64, stride = 32)"
      ],
      "metadata": {
        "id": "Y82RG-TARdMi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d356a896-6f4a-4f62-87fb-3eb21a5ae26f"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['in',\n",
              " 'basilica of the sacred heart. immediately behind the basilica',\n",
              " 'direct line that',\n",
              " 'direct line that']"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids, attention_mask = tokenizer.encode(train_subset[0]['question'], train_subset[0]['context'], max_len = 64)\n",
        "input_ids = input_ids[:64]\n",
        "attention_mask = attention_mask[:64]\n",
        "pred_answer = predict_answer(model, tokenizer, input_ids, attention_mask)\n",
        "print('eval1:',pred_answer)\n",
        "pred_answer_2 = sliding_window_inference(train_subset[0]['question'], train_subset[0]['context'], tokenizer, model, max_len = 64, stride = 32)\n",
        "print('eval2:',pred_answer_2)"
      ],
      "metadata": {
        "id": "zQOVQ-G4SM6N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d408227a-5e4c-4ad4-c612-902c5b7d3328"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eval1: in\n",
            "eval2: ['in', 'basilica of the sacred heart. immediately behind the basilica', 'direct line that', 'direct line that']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_subset = val_data.select(range(1000))\n",
        "val_dataset = QADataset(val_subset, tokenizer)\n",
        "evaluate(model, val_dataset, tokenizer,100)"
      ],
      "metadata": {
        "id": "XpHlZc38J53G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "190b05b3-11c7-4398-8acb-3e177ea23d7a"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "evaluate on 100 \n",
            "\n",
            "exact match: 0.00%\n",
            "f1 score: 3.69%\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.0, 0.03686981583287873)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_data[2]"
      ],
      "metadata": {
        "id": "GfhP2tgNCtDL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9df06f46-c429-4fea-83c1-6ad5ce44b9ac"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'id': '56be4db0acb8001400a502ee',\n",
              " 'title': 'Super_Bowl_50',\n",
              " 'context': 'Super Bowl 50 was an American football game to determine the champion of the National Football League (NFL) for the 2015 season. The American Football Conference (AFC) champion Denver Broncos defeated the National Football Conference (NFC) champion Carolina Panthers 24–10 to earn their third Super Bowl title. The game was played on February 7, 2016, at Levi\\'s Stadium in the San Francisco Bay Area at Santa Clara, California. As this was the 50th Super Bowl, the league emphasized the \"golden anniversary\" with various gold-themed initiatives, as well as temporarily suspending the tradition of naming each Super Bowl game with Roman numerals (under which the game would have been known as \"Super Bowl L\"), so that the logo could prominently feature the Arabic numerals 50.',\n",
              " 'question': 'Where did Super Bowl 50 take place?',\n",
              " 'answers': {'text': ['Santa Clara, California',\n",
              "   \"Levi's Stadium\",\n",
              "   \"Levi's Stadium in the San Francisco Bay Area at Santa Clara, California.\"],\n",
              "  'answer_start': [403, 355, 355]}}"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_dataset.data[2]['question'], val_dataset.data[2]['answers']"
      ],
      "metadata": {
        "id": "dr67xVX_CnXp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77d109fc-00a9-45aa-8a8f-a922fb2f5b67"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('Where did Super Bowl 50 take place?',\n",
              " {'text': ['Santa Clara, California',\n",
              "   \"Levi's Stadium\",\n",
              "   \"Levi's Stadium in the San Francisco Bay Area at Santa Clara, California.\"],\n",
              "  'answer_start': [403, 355, 355]})"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids, attention_mask = tokenizer.encode(val_dataset.data[2]['question'], val_dataset.data[2]['context'], max_len = 64)\n",
        "input_ids = input_ids[:64]\n",
        "attention_mask = attention_mask[:64]\n",
        "pred_answer = predict_answer(model, tokenizer, input_ids, attention_mask)\n",
        "print('eval1:',pred_answer)\n",
        "pred_answer_2 = sliding_window_inference(val_dataset.data[2]['question'], val_dataset.data[2]['context'], tokenizer, model, max_len = 64, stride = 32)\n",
        "print('eval2:',pred_answer_2)"
      ],
      "metadata": {
        "id": "GOEqUG10dCRK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69fc42bd-d58d-49c3-c480-8250c868f9fd"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eval1: (afc) champion denver broncos defeated the national football conference (nfc) champion carolina panthers 24–10 to earn their third super bowl title. the game was played\n",
            "eval2: ['(afc) champion denver broncos defeated the national football conference (nfc) champion carolina panthers 24–10 to earn their third super bowl title. the game was played', 'clara,', '', '(under which the game would have been known as \"super bowl l\"), so that the logo']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"What is KNN?\"\n",
        "context = '''KNN, or k-Nearest Neighbors, is a supervised machine learning algorithm used for both classification and regression tasks. It classifies new data points by finding the \"k\" most similar data points (neighbors) in the training data and assigning the new data point to the majority class among those neighbors.'''\n",
        "input_ids, attention_mask = tokenizer.encode(question, context, max_len = 64)\n",
        "# input_ids = input_ids[:64]\n",
        "# attention_mask = attention_mask[:64]\n",
        "pred_answer = predict_answer(model, tokenizer, input_ids, attention_mask)\n",
        "print('eval1:',pred_answer)\n",
        "pred_answer_2 = sliding_window_inference(question, context, tokenizer, model, max_len = 64, stride = 32)\n",
        "print('eval2:',pred_answer_2)"
      ],
      "metadata": {
        "id": "2uXLq9jedN0F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f00cd4de-a41a-4706-bdb9-fe8c38eb67da"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eval1: \n",
            "eval2: ['', '']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# VectorStore to store long documents / long contexts\n",
        "\n",
        "## Use KNN to retrieve documents/ contexts for questions\n",
        "\n",
        "Source: https://medium.com/@vidiptvashist/building-a-vector-database-from-scratch-in-python-6bd683ba5171\n",
        "https://sarabesh.medium.com/how-i-built-a-vector-db-with-hnsw-from-scratch-a311b6eac082\n"
      ],
      "metadata": {
        "id": "SUHDxQirv8Aa"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gKkqoWV63lr0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class knnsearch():\n",
        "  def __init__(self,k):\n",
        "    self.k = k\n",
        "\n",
        "  def cos_similarity_dist(self, vector1, vector2):\n",
        "    similarity = np.dot(vector1, vector2) / (np.linalg.norm(vector1) * np.linalg.norm(vector2))\n",
        "    return similarity\n",
        "\n",
        "  def get_neighbours(self, vector_data, query_vector):\n",
        "\n",
        "    '''\n",
        "    Get the k cloest neighbours of the query vector\n",
        "\n",
        "    input:\n",
        "      vector_data: a dictionary with query/unique id linked with its vector embedding\n",
        "      query_vector: query of interests\n",
        "\n",
        "    '''\n",
        "\n",
        "    num_neighbours = self.k\n",
        "    distances = []\n",
        "    for k,v in vector_data.items():\n",
        "      dist = self.cos_similarity_dist(query_vector, v['question_vector'])\n",
        "      distances.append((k,v['question_vector'],dist))\n",
        "\n",
        "    distances.sort(key=lambda x: x[2], reverse = True) ## Descending order here because higher cosine similairty means more similar\n",
        "    neighbours = distances[:num_neighbours]\n",
        "    return neighbours\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "leKvuo9neOkM"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class VectorStore:\n",
        "  def __init__(self):\n",
        "    self.vector_data = {} ## dictionary to store vector\n",
        "\n",
        "  def add_vector(self, vector_id, vector, context):\n",
        "    '''\n",
        "    add a vector to the store\n",
        "    vector_id: sentence of the vector\n",
        "    vector: vector data of the question\n",
        "    question_context: context of the question\n",
        "\n",
        "    '''\n",
        "    question_context = {}\n",
        "    question_context['question_vector'] = vector\n",
        "    question_context['question_context'] = context\n",
        "\n",
        "    self.vector_data[vector_id] = question_context\n",
        "\n",
        "  def get_vector(self,vector_id):\n",
        "    return self.vector_data[vector_id]['question_vector']\n",
        "\n",
        "  def get_context(self,vector_id):\n",
        "    return self.vector_data[vector_id]['question_context']\n",
        "\n",
        "\n",
        "  def knnsearch(self, query_vector, num_results = 3):\n",
        "    knn = knnsearch(num_results)\n",
        "    neighbours = knn.get_neighbours(self.vector_data, query_vector)\n",
        "    return neighbours\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "0dc21jT8eNhV"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing"
      ],
      "metadata": {
        "id": "eV9Dl8rvFMMz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# vector_store = VectorStore()  # Creating an instance of the VectorStore class\n",
        "\n",
        "# # example taken from https://medium.com/@vidiptvashist/building-a-vector-database-from-scratch-in-python-6bd683ba5171\n",
        "\n",
        "# # Define sentences\n",
        "# sentences = [  # Defining a list of example sentences\n",
        "#     \"I eat mango\",\n",
        "#     \"mango is my favorite fruit\",\n",
        "#     \"Mango is a clothing brand\",\n",
        "#     \"fruits are good for health\",\n",
        "# ]\n",
        "\n",
        "# # Tokenization and Vocabulary Creation\n",
        "# vocabulary = set()  # Initializing an empty set to store unique words\n",
        "# for sentence in sentences:  # Iterating over each sentence in the list\n",
        "#     tokens = sentence.lower().split()  # Tokenizing the sentence by splitting on whitespace and converting to lowercase\n",
        "#     vocabulary.update(tokens)  # Updating the set of vocabulary with unique tokens\n",
        "\n",
        "# # Assign unique indices to vocabulary words\n",
        "# word_to_index = {word: i for i, word in enumerate(vocabulary)}  # Creating a dictionary mapping words to unique indices\n",
        "\n",
        "# # Vectorization\n",
        "# sentence_vectors = {}  # Initializing an empty dictionary to store sentence vectors\n",
        "# for sentence in sentences:  # Iterating over each sentence in the list\n",
        "#     tokens = sentence.lower().split()  # Tokenizing the sentence by splitting on whitespace and converting to lowercase\n",
        "#     vector = np.zeros(len(vocabulary))  # Initializing a numpy array of zeros for the sentence vector\n",
        "#     for token in tokens:  # Iterating over each token in the sentence\n",
        "#         vector[word_to_index[token]] += 1  # Incrementing the count of the token in the vector\n",
        "#     sentence_vectors[sentence] = vector  # Storing the vector for the sentence in the dictionary\n",
        "\n",
        "# # Store in VectorStore\n",
        "# for sentence, vector in sentence_vectors.items():  # Iterating over each sentence vector\n",
        "#     vector_store.add_vector(sentence, vector)  # Adding the sentence vector to the VectorStore\n",
        "\n",
        "# # Similarity Search\n",
        "# query_sentence = \"Mango is the best fruit\"  # Defining a query sentence\n",
        "# query_vector = np.zeros(len(vocabulary))  # Initializing a numpy array of zeros for the query vector\n",
        "# query_tokens = query_sentence.lower().split()  # Tokenizing the query sentence and converting to lowercase\n",
        "# for token in query_tokens:  # Iterating over each token in the query sentence\n",
        "#     if token in word_to_index:  # Checking if the token is present in the vocabulary\n",
        "#         query_vector[word_to_index[token]] += 1  # Incrementing the count of the token in the query vector\n",
        "# similar_sentences = vector_store.knnsearch(query_vector, num_results=2)  # Finding 2 similar sentences\n",
        "\n",
        "# # Display similar sentences\n",
        "# print(\"Query Sentence:\", query_sentence)  # Printing the query sentence\n",
        "# print(\"Similar Sentences:\")  # Printing the header for similar sentences\n",
        "\n",
        "\n",
        "# ## Use KNN search\n",
        "# for sentence, _, similarity in similar_sentences:  # Iterating over each similar sentence and its similarity score\n",
        "#     print(f\"{sentence}: Similarity = {similarity:.4f}\")  # Printing the similar sentence and its similarity score\n",
        "\n"
      ],
      "metadata": {
        "id": "1hFdZyCC9xvT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Query Sentence: Mango is the best fruit <br>\n",
        "Similar Sentences: <br>\n",
        "mango is my favorite fruit: Similarity = 0.7746 <br>\n",
        "Mango is a clothing brand: Similarity = 0.5164 <br>\n",
        "\n",
        "Here we see that the order and the number of words contribute to similarity. But clearly the second sentence is not as similar to the query than the first candidate"
      ],
      "metadata": {
        "id": "8n4nluDbCZ0b"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rPOqDZPo-nJF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# query_sentence = \"Mango is the best fruit\"  # Defining a query sentence\n",
        "# query_vector = np.zeros(len(vocabulary))  # Initializing a numpy array of zeros for the query vector\n",
        "# query_tokens = query_sentence.lower().split()  # Tokenizing the query sentence and converting to lowercase\n",
        "# for token in query_tokens:  # Iterating over each token in the query sentence\n",
        "#     if token in word_to_index:  # Checking if the token is present in the vocabulary\n",
        "#         query_vector[word_to_index[token]] += 1  # Incrementing the count of the token in the query vector\n",
        "# query_vector"
      ],
      "metadata": {
        "id": "3sKwJzIYGJU1"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# query_tokens"
      ],
      "metadata": {
        "id": "SpPhNnoGGjVp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# word_to_index"
      ],
      "metadata": {
        "id": "mDZykbbuGpf3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# vocabulary"
      ],
      "metadata": {
        "id": "IIriffqVGUb7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# vector1 = np.array([0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 0., 1., 0., 0.])\n",
        "# vector3 = np.array([1., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0.])\n",
        "# vector4 = np.array([0., 0., 1., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0.])\n",
        "# vector2 = query_vector\n",
        "# print(np.dot(vector1, vector2) / (np.linalg.norm(vector1) * np.linalg.norm(vector2)))\n",
        "# print(np.dot(vector3, vector2) / (np.linalg.norm(vector3) * np.linalg.norm(vector2)))\n",
        "# print(np.dot(vector4, vector2) / (np.linalg.norm(vector4) * np.linalg.norm(vector2)))"
      ],
      "metadata": {
        "id": "ZCgrbRxHFqDI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74585438-475e-494b-df36-5eddbaaa437b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0\n",
            "0.2581988897471611\n",
            "0.2581988897471611\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# np.linalg.norm(vector1), np.linalg.norm(vector2),np.linalg.norm(vector3) ,np.linalg.norm(vector4)"
      ],
      "metadata": {
        "id": "pctYt3T3F4Va"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "(np.float64(2.23606797749979), <br>\n",
        " np.float64(1.7320508075688772), <br>\n",
        " np.float64(2.23606797749979), <br>\n",
        " np.float64(2.23606797749979)) <br>\n",
        "\n",
        "\n",
        "## Formula for the L2 (Euclidean) Norm of a Vector:<br>\n",
        "For a vector <br>\n",
        "\\begin{equation}\n",
        "(x=[x_{1},x_{2},...,x_{n}])\n",
        "\\end{equation},\n",
        "the L2 norm is calculated as:\n",
        "\\begin{equation}\n",
        "(\\|x\\|_{2} =\\sqrt{\\sum_{i=1}^{n}|x_{i} |^{2}})\n",
        "\\end{equation}\n",
        "This formula represents the square root of the sum of the squares of the absolute values of the vector's elements. In simpler terms, for real-valued vectors, it's the square root of the sum of the squared elements.\n",
        "\n",
        "\n",
        "## Since we are one hot encoding the sentences, sentences with the same number of word will ahve the same norm in their vectors"
      ],
      "metadata": {
        "id": "bTAFSoW5IXo7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# np.dot(vector1, vector2), np.dot(vector3, vector2), np.dot(vector4, vector2)"
      ],
      "metadata": {
        "id": "5SSoqZu_F-9i"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fill in Vector DB\n",
        "\n"
      ],
      "metadata": {
        "id": "_xfZ9JOWDJAR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# train_subset = train_data.select(range(1000))"
      ],
      "metadata": {
        "id": "Aa-VclEsclB3"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train_subset[0]"
      ],
      "metadata": {
        "id": "vcgd1ao_kHP8"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# len(train_subset)\n",
        "len(train_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DNeqY1W8pGB_",
        "outputId": "eafe73a3-6354-4efb-c4ae-4065d2439663"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "87599"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "context_cnt = {}\n",
        "for i in range(len(train_data)):\n",
        "  if train_data[i]['context'] in context_cnt:\n",
        "    context_cnt[train_data[i]['context']] +=1\n",
        "  else:\n",
        "    context_cnt[train_data[i]['context']] =1\n"
      ],
      "metadata": {
        "id": "Zq_kKNuAo4Qk"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "top_n_items = sorted(context_cnt.items(), key=lambda item: item[1], reverse=True)[:3]\n",
        "# top_n_keys = [key for key, value in top_n_items]"
      ],
      "metadata": {
        "id": "BjTZ_5S6pSIL"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "top_n_items"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xOSykkCbp8HK",
        "outputId": "a23bd265-abea-400a-c74e-f46fe72dfc87"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Victoria married her first cousin, Prince Albert of Saxe-Coburg and Gotha, in 1840. Their nine children married into royal and noble families across the continent, tying them together and earning her the sobriquet \"the grandmother of Europe\". After Albert\\'s death in 1861, Victoria plunged into deep mourning and avoided public appearances. As a result of her seclusion, republicanism temporarily gained strength, but in the latter half of her reign her popularity recovered. Her Golden and Diamond Jubilees were times of public celebration.',\n",
              "  25),\n",
              " ('In 1853, Victoria gave birth to her eighth child, Leopold, with the aid of the new anaesthetic, chloroform. Victoria was so impressed by the relief it gave from the pain of childbirth that she used it again in 1857 at the birth of her ninth and final child, Beatrice, despite opposition from members of the clergy, who considered it against biblical teaching, and members of the medical profession, who thought it dangerous. Victoria may have suffered from post-natal depression after many of her pregnancies. Letters from Albert to Victoria intermittently complain of her loss of self-control. For example, about a month after Leopold\\'s birth Albert complained in a letter to Victoria about her \"continuance of hysterics\" over a \"miserable trifle\".',\n",
              "  25),\n",
              " ('Victoria later described her childhood as \"rather melancholy\". Her mother was extremely protective, and Victoria was raised largely isolated from other children under the so-called \"Kensington System\", an elaborate set of rules and protocols devised by the Duchess and her ambitious and domineering comptroller, Sir John Conroy, who was rumoured to be the Duchess\\'s lover. The system prevented the princess from meeting people whom her mother and Conroy deemed undesirable (including most of her father\\'s family), and was designed to render her weak and dependent upon them. The Duchess avoided the court because she was scandalised by the presence of King William\\'s bastard children, and perhaps prompted the emergence of Victorian morality by insisting that her daughter avoid any appearance of sexual impropriety. Victoria shared a bedroom with her mother every night, studied with private tutors to a regular timetable, and spent her play-hours with her dolls and her King Charles spaniel, Dash. Her lessons included French, German, Italian, and Latin, but she spoke only English at home.',\n",
              "  23)]"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "[('Victoria married her first cousin, Prince Albert of Saxe-Coburg and Gotha, in 1840. Their nine children married into royal and noble families across the continent, tying them together and earning her the sobriquet \"the grandmother of Europe\". After Albert\\'s death in 1861, Victoria plunged into deep mourning and avoided public appearances. As a result of her seclusion, republicanism temporarily gained strength, but in the latter half of her reign her popularity recovered. Her Golden and Diamond Jubilees were times of public celebration.',\n",
        "  25),\n",
        " ('In 1853, Victoria gave birth to her eighth child, Leopold, with the aid of the new anaesthetic, chloroform. Victoria was so impressed by the relief it gave from the pain of childbirth that she used it again in 1857 at the birth of her ninth and final child, Beatrice, despite opposition from members of the clergy, who considered it against biblical teaching, and members of the medical profession, who thought it dangerous. Victoria may have suffered from post-natal depression after many of her pregnancies. Letters from Albert to Victoria intermittently complain of her loss of self-control. For example, about a month after Leopold\\'s birth Albert complained in a letter to Victoria about her \"continuance of hysterics\" over a \"miserable trifle\".',\n",
        "  25),\n",
        " ('Victoria later described her childhood as \"rather melancholy\". Her mother was extremely protective, and Victoria was raised largely isolated from other children under the so-called \"Kensington System\", an elaborate set of rules and protocols devised by the Duchess and her ambitious and domineering comptroller, Sir John Conroy, who was rumoured to be the Duchess\\'s lover. The system prevented the princess from meeting people whom her mother and Conroy deemed undesirable (including most of her father\\'s family), and was designed to render her weak and dependent upon them. The Duchess avoided the court because she was scandalised by the presence of King William\\'s bastard children, and perhaps prompted the emergence of Victorian morality by insisting that her daughter avoid any appearance of sexual impropriety. Victoria shared a bedroom with her mother every night, studied with private tutors to a regular timetable, and spent her play-hours with her dolls and her King Charles spaniel, Dash. Her lessons included French, German, Italian, and Latin, but she spoke only English at home.',\n",
        "  23)]\n",
        "\n",
        "\n",
        "## Story about queen victoria is the top contexts in this dataset"
      ],
      "metadata": {
        "id": "pu80Ch9IqE9o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup vector Store"
      ],
      "metadata": {
        "id": "PkTN1rbADMwp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Establish a VectorStore instance\n",
        "vector_store = VectorStore()  # Creating an instance of the VectorStore class\n",
        "max_len = 64\n",
        "linear_layer = nn.Linear(64, 1)\n",
        "# for i in range(len(train_subset)):\n",
        "#   # sentence = train_subset[i]['question']+train_subset[i]['context']\n",
        "#   sentence = train_subset[i]['context']\n",
        "  # input_ids, attention_mask = tokenizer.encode(train_subset[i]['question'], train_subset[i]['context'])\n",
        "  # input_ids, attention_mask = tokenizer.encode(train_subset[i]['question'],'')\n",
        "  # input_ids, attention_mask = tokenizer.encode(train_subset[i]['context'],'')\n",
        "  # input_ids = input_ids[:max_len]\n",
        "  # attention_mask = attention_mask[:max_len]\n",
        "  # _,_,x_embed = model(input_ids.unsqueeze(0), attention_mask.unsqueeze(0))\n",
        "  # vector_store.add_vector(sentence,linear_layer(x_embed).flatten().detach().numpy())\n",
        "\n",
        "# for i in context_cnt.keys():\n",
        "#   sentence = i\n",
        "#   input_ids, attention_mask = tokenizer.encode(i,'')\n",
        "#   input_ids = input_ids[:max_len]\n",
        "#   attention_mask = attention_mask[:max_len]\n",
        "#   _,_,x_embed = model(input_ids.unsqueeze(0), attention_mask.unsqueeze(0))\n",
        "#   vector_store.add_vector(sentence,linear_layer(x_embed).flatten().detach().numpy())\n",
        "\n",
        "for i in range(len(train_data)):\n",
        "  # sentence = train_subset[i]['question']+train_subset[i]['context']\n",
        "  sentence = train_data[i]['question']\n",
        "  context = train_data[i]['context']\n",
        "  # input_ids, attention_mask = tokenizer.encode(train_subset[i]['question'], train_subset[i]['context'])\n",
        "  input_ids, attention_mask = tokenizer.encode(train_data[i]['question'],'')\n",
        "  # input_ids, attention_mask = tokenizer.encode(train_subset[i]['context'],'')\n",
        "  input_ids = input_ids[:max_len]\n",
        "  attention_mask = attention_mask[:max_len]\n",
        "  _,_,x_embed = model(input_ids.unsqueeze(0), attention_mask.unsqueeze(0))\n",
        "  question_vector = linear_layer(x_embed).flatten().detach().numpy()\n",
        "  # add_vector(self, vector_id, vector, context)\n",
        "  vector_store.add_vector(sentence,question_vector, context)"
      ],
      "metadata": {
        "id": "jJh8vccr9u3y"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "xCLxKPh4lKoE",
        "outputId": "270f8e24-8d49-42f1-f50c-b0cc32582925"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'What is KMC an initialism of?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dict_iterator = iter(vector_store.vector_data.items())\n",
        "first_item = next(dict_iterator)"
      ],
      "metadata": {
        "id": "2rARB5mBGGdG"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "first_item"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "URLbBlph23fw",
        "outputId": "f572b547-9a9d-4709-c87b-ce268f821bc7"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?',\n",
              " {'question_vector': array([ 0.30114734,  0.13924202,  0.16156885,  0.15640429,  0.29231155,\n",
              "          0.09760544,  0.16844174, -0.06137094,  0.16680655, -0.5400078 ,\n",
              "          1.1729724 , -0.80211735, -1.0606651 , -1.4569314 , -0.40364388,\n",
              "         -0.5613744 ,  0.13703218,  0.06845745,  0.1583049 ,  0.09146819,\n",
              "          0.08771393,  0.08044299, -0.02138761,  0.10931954, -0.05400237,\n",
              "          0.18152538,  0.12233892,  0.12023988,  0.07714114,  0.19235924,\n",
              "          0.02517417,  0.40140757,  0.19371954,  0.09658667,  0.05951884,\n",
              "          0.02944812,  0.3376676 , -0.00156459,  0.11715952,  0.11889163,\n",
              "          0.16627038,  0.10894796,  0.24635258,  0.1424909 ,  0.00969532,\n",
              "          0.11651799,  0.09652635,  0.1958901 ,  0.15266433,  0.05725852,\n",
              "          0.14630896,  0.19310269,  0.01369265,  0.11033431,  0.22886899,\n",
              "          0.1692011 ,  0.13666573,  0.1726332 ,  0.13150641,  0.25053063,\n",
              "          0.07857087,  0.04994443,  0.13610694,  0.11334476], dtype=float32),\n",
              "  'question_context': 'Architecturally, the school has a Catholic character. Atop the Main Building\\'s gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.'})"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing\n",
        "# dict_iterator = iter(vector_store.vector_data.items())\n",
        "# first_item = next(dict_iterator)\n",
        "#  first_item\n",
        "# first_item[1].shape\n",
        "# # v1 = torch.cat([emb for emb in first_item[1]])\n",
        "# v1 = first_item[1].flatten()\n",
        "# v2 = first_item[1].flatten()\n",
        "# v1 = v1.detach().numpy()\n",
        "# v2 = v2.detach().numpy()\n",
        "# print(np.dot(v2, v1) / (np.linalg.norm(v2) * np.linalg.norm(v1)))"
      ],
      "metadata": {
        "id": "yZqgQgDlfB2A"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Similarity Search\n",
        "# query_sentence = 'Who is Beyonce?' # Defining a query sentence\n",
        "query_sentence = 'To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?'\n",
        "# query_sentence = 'Who is virgin mary?'\n",
        "input_ids, attention_mask = tokenizer.encode(query_sentence,'')\n",
        "input_ids = input_ids[:max_len]\n",
        "attention_mask = attention_mask[:max_len]\n",
        "_,_,x_embed = model(input_ids.unsqueeze(0), attention_mask.unsqueeze(0))\n",
        "query_vector = linear_layer(x_embed).flatten().detach().numpy()\n",
        "similar_sentences = vector_store.knnsearch(query_vector, num_results=5)\n"
      ],
      "metadata": {
        "id": "uvQhkmaTFXCo"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ## Use KNN search\n",
        "for sentence, _, similarity in similar_sentences:  # Iterating over each similar sentence and its similarity score\n",
        "    print(f\"{sentence}: Similarity = {similarity:.4f}\")  # Printing the similar sentence and its similarity score\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q2JTSA3i4Y0_",
        "outputId": "0d1eee77-1107-4b68-8c66-3f35ecbd8a02"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?: Similarity = 1.0000\n",
            "Unlike English, both German and Dutch use how many genders in their grammar?: Similarity = 0.9290\n",
            "In degrees Fahrenheit, what is the normal range of high temperatures in Miami?: Similarity = 0.9188\n",
            "What model solved the problem of databases where information was missing?: Similarity = 0.9110\n",
            "When did black Baptists began to organize separate churches, associations and mission agencies?: Similarity = 0.8958\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "similar_sentences[0][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "cZWkosf-4X-a",
        "outputId": "6ba6268c-3c94-455a-d184-2aaaa9d4e8e2"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vector_store.get_context(similar_sentences[0][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "2YXAPuaR3hYL",
        "outputId": "449d957f-60da-412e-ffee-27e93c7931da"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Architecturally, the school has a Catholic character. Atop the Main Building\\'s gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Putting everything together"
      ],
      "metadata": {
        "id": "YrvHtfEaJyF7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## First choose a question\n",
        "\n",
        "question = val_dataset.data[3]['question']\n",
        "print(val_dataset.data[3]['question'])\n",
        "print(val_dataset.data[3]['context'])\n",
        "print(val_dataset.data[3]['answers'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vitLR6v-6Kdu",
        "outputId": "5b494b3e-9901-4b0d-bc08-18214cfc0392"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Which NFL team won Super Bowl 50?\n",
            "Super Bowl 50 was an American football game to determine the champion of the National Football League (NFL) for the 2015 season. The American Football Conference (AFC) champion Denver Broncos defeated the National Football Conference (NFC) champion Carolina Panthers 24–10 to earn their third Super Bowl title. The game was played on February 7, 2016, at Levi's Stadium in the San Francisco Bay Area at Santa Clara, California. As this was the 50th Super Bowl, the league emphasized the \"golden anniversary\" with various gold-themed initiatives, as well as temporarily suspending the tradition of naming each Super Bowl game with Roman numerals (under which the game would have been known as \"Super Bowl L\"), so that the logo could prominently feature the Arabic numerals 50.\n",
            "{'text': ['Denver Broncos', 'Denver Broncos', 'Denver Broncos'], 'answer_start': [177, 177, 177]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Get its related context from the vector DB\n",
        "input_ids, attention_mask = tokenizer.encode(question,'')\n",
        "input_ids = input_ids[:max_len]\n",
        "attention_mask = attention_mask[:max_len]\n",
        "_,_,x_embed = model(input_ids.unsqueeze(0), attention_mask.unsqueeze(0))\n",
        "query_vector = linear_layer(x_embed).flatten().detach().numpy()\n",
        "similar_sentences = vector_store.knnsearch(query_vector, num_results=5)\n",
        "for sentence, _, similarity in similar_sentences:  # Iterating over each similar sentence and its similarity score\n",
        "    print(f\"{sentence}: Similarity = {similarity:.4f}\")  # Printing the similar sentence and its similarity score\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "39RBMzaN6TZe",
        "outputId": "c71c31f4-00ad-4dd2-d070-5e4c7e766106"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cinnabar is an ore of what metal?: Similarity = 0.9432\n",
            "Who founded the Order of St. George?: Similarity = 0.9335\n",
            "What metropolitan area has the largest population?: Similarity = 0.9334\n",
            "Where is the Gold State Coach kept?: Similarity = 0.9280\n",
            "Which navy won the battle of Hydra?: Similarity = 0.9239\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vector_store.get_context(similar_sentences[0][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "BJbqbDtV85Px",
        "outputId": "eed28c49-d40b-4bac-a6fb-f6e23617a7e2"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The Romans liked bright colors, and many Roman villas were decorated with vivid red murals. The pigment used for many of the murals was called vermilion, and it came from the mineral cinnabar, a common ore of mercury. It was one of the finest reds of ancient times – the paintings have retained their brightness for more than twenty centuries. The source of cinnabar for the Romans was a group of mines near Almadén, southwest of Madrid, in Spain. Working in the mines was extremely dangerous, since mercury is highly toxic; the miners were slaves or prisoners, and being sent to the cinnabar mines was a virtual death sentence.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "context = vector_store.get_context(similar_sentences[0][0])\n",
        "input_ids, attention_mask = tokenizer.encode(question, context, max_len = 64)\n",
        "input_ids = input_ids[:64]\n",
        "attention_mask = attention_mask[:64]\n",
        "pred_answer = predict_answer(model, tokenizer, input_ids, attention_mask)\n",
        "print('eval1:',pred_answer)\n",
        "pred_answer_2 = sliding_window_inference(question, context, tokenizer, model, max_len = 64, stride = 32)\n",
        "print('eval2:',pred_answer_2)"
      ],
      "metadata": {
        "id": "2pXsQkAVOFxN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41222f0b-16c0-4fbb-b1a4-f7eb09a4df47"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eval1: roman villas were decorated with vivid red murals. the pigment\n",
            "eval2: ['roman villas were decorated with vivid red murals. the pigment', 'mines', 'toxic; the miners were slaves or prisoners,', '']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "context = val_dataset.data[3]['context']\n",
        "\n",
        "input_ids, attention_mask = tokenizer.encode(question, context, max_len = 64)\n",
        "input_ids = input_ids[:64]\n",
        "attention_mask = attention_mask[:64]\n",
        "\n",
        "pred_answer = predict_answer(model, tokenizer, input_ids, attention_mask)\n",
        "print('eval1:',pred_answer)\n",
        "pred_answer_2 = sliding_window_inference(val_dataset.data[3]['question'], val_dataset.data[3]['context'], tokenizer, model, max_len = 64, stride = 32)\n",
        "print('eval2:',pred_answer_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ebN2li0tD-e9",
        "outputId": "6c84bf1f-acfe-407c-f4cd-cadd6a4fc64e"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eval1: (nfc) champion carolina panthers 24–10 to earn their third super bowl title. the game was played\n",
            "eval2: ['(nfc) champion carolina panthers 24–10 to earn their third super bowl title. the game was played', '', 'numerals', '(under which the game would have been known as \"super bowl l\"), so that the logo']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnt = 0\n",
        "for i in context_cnt.keys():\n",
        "  if 'super bowl' in i or \"Super Bowl\" in i:\n",
        "    cnt+=1\n",
        "\n",
        "print(cnt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Vc0FrBKCOWh",
        "outputId": "e42190a9-a4d7-46da-93bc-b8ff1ad66034"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Only 15 context in the training subset has \"super bowl\" mentioned in training dataset. vector store did not get the correct context"
      ],
      "metadata": {
        "id": "45DzvzgnCXyG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TO DO\n",
        "* analyze the SQuAD dataset\n",
        "* use better contextual embedding from pre-trained models\n",
        "* Evaluate retriever\n",
        "* Add and evaluate reader"
      ],
      "metadata": {
        "id": "nOnTD8vwDzDj"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MnIXLSRr-rWC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}