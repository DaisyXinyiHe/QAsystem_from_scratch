{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# A Simple transformer question and answer model needs:\n",
        "* Tokinizer (Here i am using BERT's way to tokenize beginning and end of sentences)\n",
        "* Transformer encoder\n",
        "* QA head (predict start and end position)\n",
        "* Training and inference logic\n",
        "\n"
      ],
      "metadata": {
        "id": "F64zJ7O3cbSn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Use self-built attention head"
      ],
      "metadata": {
        "id": "bLQxgKC9j5SV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PTfvlb4ObTv1"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import math\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "config = {\n",
        "        \"vocab_size\": 45,\n",
        "        \"hidden_size\": 64,\n",
        "        \"max_position_embeddings\": 64,\n",
        "        \"num_attention_heads\": 4,\n",
        "        'intermediate_size':10,\n",
        "        'hidden_dropout_prob':0.01,\n",
        "        \"num_hidden_layers\": 12,\n",
        "        'mask':None\n",
        "    }"
      ],
      "metadata": {
        "id": "MBvVdTLxGQYw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Tokinizer\n",
        "\n",
        "class SimpleTokinizer:\n",
        "  def __init__(self):\n",
        "    self.vocab = {\"[PAD]\":0, \"[CLS]\":1, \"[SEP]\":2,\"[UNK]\":3}\n",
        "    self.reverse_vocab = {0:\"[PAD]\", 1:\"[CLS]\", 2:\"[SEP]\",3:\"[UNK]\"}\n",
        "    self.idx = 4\n",
        "\n",
        "  def build_vocab(self,texts):\n",
        "    for text in texts:\n",
        "      for word in text.lower().split():\n",
        "        if word not in self.vocab:\n",
        "          self.vocab[word] = self.idx\n",
        "          self.reverse_vocab[self.idx] = word\n",
        "          self.idx+=1\n",
        "  def encode(self, question, contaxt, max_len = 64):\n",
        "    ## for each QA, input takes format of [CLS] question tokens [SEP] context tokens [SEP]\n",
        "    tokens = [\"[CLS]\"]+question.lower().split()+[\"[SEP]\"]+contaxt.lower().split()+[\"[SEP]\"]\n",
        "    token_ids = [self.vocab.get(token, self.vocab[\"[UNK]\"]) for token in tokens]\n",
        "    token_type_ids = [1]*(len(question.split())+2)+[2]*(len(context.split())+1)\n",
        "    attention_mask = [1] * len(token_ids)\n",
        "    padding = [0]*(max_len - len(token_ids))\n",
        "    # print(token_type_ids)\n",
        "    return {\n",
        "        'input_ids':torch.tensor(token_ids + padding[:max_len - len(token_ids)]),\n",
        "        'attention_mask':torch.tensor(attention_mask+padding[:max_len - len(token_ids)]),\n",
        "        'token':tokens+['[PAD]']*len(padding),\n",
        "        'token_type_ids':torch.tensor(token_type_ids+padding[:max_len - len(token_ids)]),\n",
        "\n",
        "    }"
      ],
      "metadata": {
        "id": "AWoGbLg3cehF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Sample\n",
        "question = \"What is KNN?\"\n",
        "context = '''KNN, or k-Nearest Neighbors, is a supervised machine learning algorithm used for both classification and regression tasks. It classifies new data points by finding the \"k\" most similar data points (neighbors) in the training data and assigning the new data point to the majority class among those neighbors.'''\n"
      ],
      "metadata": {
        "id": "sM_MmMgWGd8-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Tokenizer\n",
        "tokenizer = SimpleTokinizer()\n",
        "tokenizer.build_vocab([question, context])\n",
        "# input_ids, attention_mask = tokenizer.encode(question, context)\n",
        "inputs = tokenizer.encode(question, context)"
      ],
      "metadata": {
        "id": "ZsVyzA_WGd8-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# inputs"
      ],
      "metadata": {
        "id": "lN_yR2g3TJMD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# input_ids = input_ids.unsqueeze(0)\n",
        "# attention_mask = attention_mask.unsqueeze(0)"
      ],
      "metadata": {
        "id": "hbgu9-c2J8zo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# config['mask'] = attention_mask"
      ],
      "metadata": {
        "id": "YYsPnOP2RGZn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# input_ids.shape, attention_mask.shape"
      ],
      "metadata": {
        "id": "SUcbVzSYKz-l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Atttention head\n",
        "\n",
        "def scaled_dot_product_attention(q,k,v, mask = None):\n",
        "  # print(q.shape,k.shape,v.shape)\n",
        "  dim_k = k.size(-1) ## embedding size\n",
        "  # print(dim_k)\n",
        "  # print(k.transpose(1,2).shape)\n",
        "  scores = torch.bmm(q,k.transpose(1,2)) / math.sqrt(dim_k)\n",
        "  if mask is not None:\n",
        "    scores = scores.masked_fill(mask==0, -float('inf'))\n",
        "  weights = F.softmax(scores, dim=1)\n",
        "  attention_outputs = torch.bmm(weights, v)\n",
        "  return attention_outputs\n",
        "\n",
        "\n",
        "class AttentionHead(nn.Module):\n",
        "  def __init__(self, embed_dim, head_dim, mask=None):\n",
        "    super().__init__()\n",
        "    self.q = nn.Linear(embed_dim, head_dim)\n",
        "    self.k = nn.Linear(embed_dim, head_dim)\n",
        "    self.v = nn.Linear(embed_dim, head_dim)\n",
        "    self.mask = mask\n",
        "\n",
        "  def forward(self,hidden_state):\n",
        "    attention_outputs = scaled_dot_product_attention(self.q(hidden_state),self.k(hidden_state),self.v(hidden_state), mask = self.mask)\n",
        "\n",
        "    return attention_outputs\n",
        "\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "  def __init__(self,config):\n",
        "    super().__init__()\n",
        "    embed_dim = config['hidden_size']\n",
        "    num_heads = config['num_attention_heads']\n",
        "    head_dim = embed_dim // num_heads\n",
        "    mask = config['mask']\n",
        "    self.heads = nn.ModuleList(\n",
        "        [AttentionHead(embed_dim, head_dim, mask) for _ in range(num_heads)]\n",
        "    )\n",
        "    self.output_linear = nn.Linear(embed_dim, embed_dim)\n",
        "\n",
        "  def forward(self,hidden_state):\n",
        "    # print(hidden_state.shape)\n",
        "    # for h in self.heads:\n",
        "    #   print(h(hidden_state)[0][0].shape)\n",
        "    # print(self.heads)\n",
        "    x = torch.cat([h(hidden_state) for h in self.heads], dim = -1)\n",
        "    x = self.output_linear(x)\n",
        "    return x\n",
        "\n"
      ],
      "metadata": {
        "id": "upj8B52_feAm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "AttentionHead(config['hidden_size'], config['num_attention_heads'], config['mask'])"
      ],
      "metadata": {
        "id": "JcksK0yqYRfR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "multihead_attn = MultiHeadAttention(config)\n",
        "token_emb = nn.Embedding(config['vocab_size'], config['hidden_size'])\n",
        "input_embeds = token_emb(inputs['input_ids'])\n",
        "input_embeds = input_embeds.unsqueeze(0)\n",
        "attn_output = multihead_attn(input_embeds)"
      ],
      "metadata": {
        "id": "dIL-noipHAsb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FeedForward(nn.Module):\n",
        "  def __init__(self, config):\n",
        "    super().__init__()\n",
        "    self.linear1 = nn.Linear(config['hidden_size'], config['intermediate_size'])\n",
        "    self.linear2 = nn.Linear(config['intermediate_size'], config['hidden_size'])\n",
        "    self.gelu = nn.GELU()\n",
        "    self.dropout = nn.Dropout(config['hidden_dropout_prob'])\n",
        "\n",
        "  def forward(self,x):\n",
        "    x = self.linear1(x)\n",
        "    x = self.gelu(x)\n",
        "    x = self.linear2(x)\n",
        "    x = self.dropout(x)\n",
        "    return x\n"
      ],
      "metadata": {
        "id": "jGqt0bAug0Vi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feed_forward = FeedForward(config)"
      ],
      "metadata": {
        "id": "DKwjjqd0PTjK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ff_outputs = feed_forward(attn_output)"
      ],
      "metadata": {
        "id": "_S64BQZvPVG7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ff_outputs.shape"
      ],
      "metadata": {
        "id": "rk4RkliVPWXN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerEncoderLayer(nn.Module):\n",
        "  def __init__(self,config):\n",
        "    super().__init__()\n",
        "    self.layer_norm1 = nn.LayerNorm(config['hidden_size'])\n",
        "    self.layer_norm2 = nn.LayerNorm(config['hidden_size'])\n",
        "    self.attention = MultiHeadAttention(config)\n",
        "    self.feedforward = FeedForward(config)\n",
        "  def forward(self, x):\n",
        "    hidden_state = self.layer_norm1(x)\n",
        "    atten_output =  self.attention(hidden_state)\n",
        "    x+=atten_output\n",
        "    x += self.feedforward(self.layer_norm2(x))\n",
        "    return x\n"
      ],
      "metadata": {
        "id": "6brH7YThmSMh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_layer = TransformerEncoderLayer(config)\n",
        "print(input_embeds.shape)\n",
        "encoder_layer(input_embeds).shape"
      ],
      "metadata": {
        "id": "E_9yHmzsPZ6d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Embeddings(nn.Module):\n",
        "  def __init__(self,config):\n",
        "    super().__init__()\n",
        "    self.token_embeddings = nn.Embedding(config['vocab_size'], config['hidden_size'])\n",
        "    self.position_embeddings = nn.Embedding(config['max_position_embeddings'], config['hidden_size'])\n",
        "    self.layer_norm = nn.LayerNorm(config['hidden_size'], eps = 1e-12)\n",
        "    self.dropout = nn.Dropout()\n",
        "\n",
        "  def forward(self, input_ids):\n",
        "    seq_length = input_ids.unsqueeze(0).size(1)\n",
        "    position_ids = torch.arange(seq_length, dtype = torch.long).unsqueeze(0)\n",
        "    # print(input_ids)\n",
        "    token_embeddings = self.token_embeddings(input_ids)\n",
        "    position_embeddings = self.position_embeddings(position_ids)\n",
        "    embeddings = token_embeddings+position_embeddings\n",
        "    embeddings = self.layer_norm(embeddings)\n",
        "    embeddings = self.dropout(embeddings)\n",
        "    return embeddings\n",
        "\n"
      ],
      "metadata": {
        "id": "VQ4V-vC92JPH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_layer = Embeddings(config)\n",
        "embedding_layer(inputs['input_ids'])#.size()"
      ],
      "metadata": {
        "id": "jriCgnyGbYBy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerEncoder(nn.Module):\n",
        "  def __init__(self, config):\n",
        "    super().__init__()\n",
        "    self.embeddings = Embeddings(config)\n",
        "    self.layers = nn.ModuleList(\n",
        "        [TransformerEncoderLayer(config) for _ in range(config['num_hidden_layers'])]\n",
        "    )\n",
        "  def forward(self,x):\n",
        "    x = self.embeddings(x)\n",
        "    for layer in self.layers:\n",
        "      # print(layer)\n",
        "      x = layer(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "oMlQ6Sq14Lyz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = TransformerEncoder(config)\n",
        "encoder(inputs['input_ids']).size()"
      ],
      "metadata": {
        "id": "fkKToZBH6dRx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Add a QA head\n",
        "class QA_Transformer(nn.Module):\n",
        "  def __init__(self, vocab_size, d_model = 64, max_len = 64, heads = 4):\n",
        "    super().__init__()\n",
        "    self.config = {\n",
        "        \"vocab_size\": vocab_size,\n",
        "        \"hidden_size\": d_model,\n",
        "        \"max_position_embeddings\": max_len,\n",
        "        \"num_attention_heads\": heads,\n",
        "        'intermediate_size':10,\n",
        "        'hidden_dropout_prob':0.01,\n",
        "        \"num_hidden_layers\": 12,\n",
        "        'mask':None\n",
        "    }\n",
        "    # self.embedding = nn.Embedding(self.config['vocab_size'], self.config['hidden_size'])\n",
        "    self.encoder = TransformerEncoder(self.config)\n",
        "    # self.position_embeddings = nn.Parameter(torch.randn(1, self.config['max_position_embeddings'], self.config['hidden_size']))\n",
        "    # self.position_embeddings = nn.Parameter(torch.randint(1, self.config['max_position_embeddings'], self.config['hidden_size']))\n",
        "    self.qa_outputs = nn.Linear(self.config['hidden_size'], 2)\n",
        "\n",
        "  def forward(self, input_ids):#, attention_mask):\n",
        "    input_ids = input_ids.unsqueeze(0)\n",
        "    # attention_mask = attention_mask.unsqueeze(0)\n",
        "    # x = self.embedding(input_ids)+self.position_embeddings[:,:input_ids.size(1)]#.long()\n",
        "    x = self.encoder(input_ids)#, attention_mask)\n",
        "    logits = self.qa_outputs(x)\n",
        "    start_logits, end_logits = logits.split(1,dim=-1)\n",
        "    return start_logits.squeeze(-1), end_logits.squeeze(-1)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "MpKwDhBJ4nnF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Sample\n",
        "question = \"What is KNN?\"\n",
        "context = '''KNN, or k-Nearest Neighbors, is a supervised machine learning algorithm used for both classification and regression tasks. It classifies new data points by finding the \"k\" most similar data points (neighbors) in the training data and assigning the new data point to the majority class among those neighbors.'''\n"
      ],
      "metadata": {
        "id": "Lo3ZcEw56mP1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Tokenizer\n",
        "tokenizer = SimpleTokinizer()\n",
        "tokenizer.build_vocab([question, context])\n",
        "# input_ids, attention_mask = tokenizer.encode(question, context)\n",
        "# input_ids = input_ids.unsqueeze(0)\n",
        "# attention_mask = attention_mask.unsqueeze(0)\n",
        "input = tokenizer.encode(question, context)"
      ],
      "metadata": {
        "id": "D3ItMBvZ7RY_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# input['input_ids']"
      ],
      "metadata": {
        "id": "CTa0zsmO7oOt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input['attention_mask'].shape, input['input_ids'].shape, len(tokenizer.vocab)"
      ],
      "metadata": {
        "id": "D_uBD0-07qi7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input['input_ids'].shape"
      ],
      "metadata": {
        "id": "XonPcqt9e5z6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Model\n",
        "model = QA_Transformer(vocab_size =len(tokenizer.vocab), d_model = 64, max_len = 64, heads = 4)\n",
        "# start_logits, end_logits = model(input_ids.unsqueeze(0), attention_mask.unsqueeze(0))\n",
        "start_logits, end_logits = model(input['input_ids'])#, input['attention_mask'])"
      ],
      "metadata": {
        "id": "iVqu2XY370pb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# start_logits, end_logits"
      ],
      "metadata": {
        "id": "v205VN5Ok9tB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get answer span\n",
        "start_idx = torch.argmax(start_logits, dim=1).item()\n",
        "end_idx = torch.argmax(end_logits, dim=1).item()\n",
        "print(start_idx, end_idx)\n",
        "tokens = inputs['input_ids'].tolist()\n",
        "# print(tokens)\n",
        "answer = [tokenizer.reverse_vocab.get(t, '[UNK]') for t in tokens[start_idx:end_idx+1]]\n",
        "print(\"Predicted answer:\", \" \".join(answer))"
      ],
      "metadata": {
        "id": "dqyflOz6lC6e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model has not been trained yet and no seed is set so output is very unstable\n",
        "\n",
        "### Output from the above:\n",
        "46 58\n",
        "Predicted answer: to the majority class among those neighbors. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
        "\n",
        "### But sometimes it could be empty."
      ],
      "metadata": {
        "id": "k5IvGBMglWoX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Existing attention head from pytorch"
      ],
      "metadata": {
        "id": "oyHHQQOQjz-Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleTokenizer:\n",
        "    def __init__(self):\n",
        "        self.vocab = {\"[PAD]\": 0, \"[CLS]\": 1, \"[SEP]\": 2, \"[UNK]\": 3}\n",
        "        self.reverse_vocab = {0: \"[PAD]\", 1: \"[CLS]\", 2: \"[SEP]\", 3: \"[UNK]\"}\n",
        "        self.idx = 4\n",
        "\n",
        "    def build_vocab(self, texts):\n",
        "        for text in texts:\n",
        "            for word in text.lower().split():\n",
        "                if word not in self.vocab:\n",
        "                    self.vocab[word] = self.idx\n",
        "                    self.reverse_vocab[self.idx] = word\n",
        "                    self.idx += 1\n",
        "\n",
        "    def encode(self, question, context, max_len=64):\n",
        "        tokens = [\"[CLS]\"] + question.lower().split() + [\"[SEP]\"] + context.lower().split() + [\"[SEP]\"]\n",
        "        token_ids = [self.vocab.get(token, self.vocab[\"[UNK]\"]) for token in tokens]\n",
        "        attention_mask = [1] * len(token_ids)\n",
        "        padding = [0] * (max_len - len(token_ids))\n",
        "        return (\n",
        "            torch.tensor(token_ids + padding[:max_len - len(token_ids)]),\n",
        "            torch.tensor(attention_mask + padding[:max_len - len(token_ids)])\n",
        "        )\n"
      ],
      "metadata": {
        "id": "FL2SroxwguIm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self, dim, heads):\n",
        "        super().__init__()\n",
        "        self.attn = nn.MultiheadAttention(embed_dim=dim, num_heads=heads, batch_first=True)\n",
        "        self.norm1 = nn.LayerNorm(dim)\n",
        "        self.ff = nn.Sequential(\n",
        "            nn.Linear(dim, dim * 4),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(dim * 4, dim)\n",
        "        )\n",
        "        self.norm2 = nn.LayerNorm(dim)\n",
        "\n",
        "    def forward(self, x, mask):\n",
        "        # print(x)\n",
        "        attn_output, _ = self.attn(x, x, x, key_padding_mask=~mask.bool())\n",
        "        # print(attn_output)\n",
        "        x = self.norm1(x + attn_output)\n",
        "        ff_output = self.ff(x)\n",
        "        x = self.norm2(x + ff_output)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "VFCJLB62-df4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class QA_Transformer(nn.Module):\n",
        "    def __init__(self, vocab_size, d_model=64, max_len=64, heads=4):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
        "        self.pos_embedding = nn.Parameter(torch.randn(1, max_len, d_model))\n",
        "        self.encoder = TransformerBlock(d_model, heads)\n",
        "        self.qa_outputs = nn.Linear(d_model, 2)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        x = self.embedding(input_ids) + self.pos_embedding[:, :input_ids.size(1)]\n",
        "        # print(x.shape)\n",
        "        x = self.encoder(x, attention_mask)\n",
        "        # print(x.shape)\n",
        "        logits = self.qa_outputs(x)  # [batch, seq_len, 2]\n",
        "        start_logits, end_logits = logits.split(1, dim=-1)\n",
        "        return start_logits.squeeze(-1), end_logits.squeeze(-1)\n"
      ],
      "metadata": {
        "id": "lTtXqNwigl-7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample data\n",
        "question = \"What is KNN?\"\n",
        "context = '''KNN, or k-Nearest Neighbors, is a supervised machine learning algorithm used for both classification and regression tasks. It classifies new data points by finding the \"k\" most similar data points (neighbors) in the training data and assigning the new data point to the majority class among those neighbors.'''\n",
        "\n",
        "\n",
        "# Tokenizer\n",
        "tokenizer = SimpleTokenizer()\n",
        "tokenizer.build_vocab([question, context])\n",
        "input_ids, attention_mask = tokenizer.encode(question, context)\n",
        "\n",
        "# Model\n",
        "model = QA_Transformer(vocab_size=len(tokenizer.vocab))\n",
        "start_logits, end_logits = model(input_ids.unsqueeze(0), attention_mask.unsqueeze(0))\n",
        "\n",
        "# Get answer span\n",
        "start_idx = torch.argmax(start_logits, dim=1).item()\n",
        "end_idx = torch.argmax(end_logits, dim=1).item()\n",
        "tokens = input_ids.tolist()\n",
        "answer = [tokenizer.reverse_vocab.get(t, '[UNK]') for t in tokens[start_idx:end_idx+1]]\n",
        "print(\"Predicted answer:\", \" \".join(answer))\n"
      ],
      "metadata": {
        "id": "aQWToSpdgndv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "attention_mask"
      ],
      "metadata": {
        "id": "P08qZCBsgo5O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tokens[start_idx:end_idx+1]"
      ],
      "metadata": {
        "id": "RGac9X73gzOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model has not been trained yet and no seed is set so output is very unstable\n",
        "\n",
        "### output from above:\n",
        "Predicted answer: is a supervised machine learning algorithm used for both classification and regression tasks. it classifies new data points\n",
        "\n",
        "### But another run will be different\n",
        "### Model needs to be trained and set seeds"
      ],
      "metadata": {
        "id": "Vh_5Dw3ilckK"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lfvHyPD4hhLO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train model with SQuAD data"
      ],
      "metadata": {
        "id": "p2G6AEDSwZov"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)"
      ],
      "metadata": {
        "id": "6w2O6C6cKmue"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "id": "23G6byOMwcEL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "## Load SQuAD data\n",
        "squad = load_dataset('squad')"
      ],
      "metadata": {
        "id": "igidq2_zwdeX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "squad"
      ],
      "metadata": {
        "id": "6GmNewbmw_Ql"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = squad['train']\n",
        "val_data =squad['validation']"
      ],
      "metadata": {
        "id": "b381jPT9wtT5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data"
      ],
      "metadata": {
        "id": "1H8kiG4lw8fs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_data"
      ],
      "metadata": {
        "id": "32p85c-3w9oy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data[200]"
      ],
      "metadata": {
        "id": "vTwR2d_owzFD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_data[100]['question']"
      ],
      "metadata": {
        "id": "zC33AYdUw1Nq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def char_to_token_span(context, answer_start, answer_text, tokenizer):\n",
        "  words = context.lower().split()\n",
        "  char_idx = 0\n",
        "  token_start = token_end = -1\n",
        "  for i, word in enumerate(words):\n",
        "    if context.lower().find(answer_text.lower(), char_idx) != -1:\n",
        "      char_idx = context.lower().find(answer_text.lower(),char_idx)\n",
        "      token_start = len(context[:char_idx].split())\n",
        "      token_end = token_start+len(answer_text.split()) - 1\n",
        "      break\n",
        "  return token_start, token_end"
      ],
      "metadata": {
        "id": "XDP-Qbo_xEvU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build vocab from all texts in train + validation\n",
        "tokenizer = SimpleTokenizer()\n",
        "all_texts = []\n",
        "for item in train_data:\n",
        "    all_texts.extend([item[\"question\"], item[\"context\"]])\n",
        "tokenizer.build_vocab(all_texts)\n",
        "\n",
        "for item in val_data:\n",
        "    all_texts.extend([item[\"question\"], item[\"context\"]])\n",
        "tokenizer.build_vocab(all_texts)"
      ],
      "metadata": {
        "id": "YTnmpFfVyWC6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class QADataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, data, tokenizer, max_len=64, doc_stride = 32):\n",
        "        self.data = data\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "        self.samples = []\n",
        "        self.doc_stride = doc_stride\n",
        "\n",
        "        for item in data:\n",
        "            q = item[\"question\"]\n",
        "            c = item[\"context\"]\n",
        "            a = item[\"answers\"][\"text\"][0]\n",
        "            a_start = item[\"answers\"][\"answer_start\"][0]\n",
        "            self.tokenizer.build_vocab([q, c])\n",
        "            input_ids, attn_mask = tokenizer.encode(q, c, max_len)\n",
        "            start, end = char_to_token_span(c, a_start, a, tokenizer)\n",
        "\n",
        "            # Adjust for [CLS] and question tokens\n",
        "            offset = 1 + len(q.split()) + 1\n",
        "            start += offset\n",
        "            end += offset\n",
        "            # print(end, max_len)\n",
        "            if end < max_len:\n",
        "              # print('end<max_len')\n",
        "              self.samples.append((input_ids, attn_mask, start, end))\n",
        "\n",
        "            else:\n",
        "\n",
        "              q_tokens = q.split()\n",
        "              c_tokens = c.split()\n",
        "\n",
        "              ## Sliding window over the context to deal with long context\n",
        "              doc_start = 0\n",
        "              # print(q,c,a)\n",
        "              while doc_start < len(c_tokens):\n",
        "\n",
        "                doc_end = min(doc_start+(max_len - len(q_tokens) - 3), len(c_tokens))\n",
        "                # (max_len - len(q_tokens) - 3) because we need to add question tokens and [cls] [sep] [sep] into the total doc feeding into the model.\n",
        "                # Format input will be like this: [cls] question tokens [sep] context tokens [sep]\n",
        "                # print(doc_start, doc_end,len(c_tokens))\n",
        "                # print(c_tokens[doc_start:doc_end])\n",
        "                # Check if the answer is inside this chunk\n",
        "                if start >= doc_start and end <= doc_end:\n",
        "                  # Adjust answer positions relative to this chunk because now it changes\n",
        "                  adj_start = start - doc_start\n",
        "                  adj_end = end - doc_start\n",
        "\n",
        "                  ## input\n",
        "                  new_context = ' '.join(c_tokens[doc_start:doc_end])\n",
        "                  self.tokenizer.build_vocab([q, new_context])\n",
        "                  input_ids, attn_mask = tokenizer.encode(q, new_context, max_len)\n",
        "                  offset = 1+len(q_tokens)+1\n",
        "                  start_pos = adj_start+offset\n",
        "                  end_pos = adj_end+offset\n",
        "                  # print(start_pos, end_pos)\n",
        "                  self.samples.append((input_ids, attn_mask, start_pos, end_pos))\n",
        "\n",
        "                if doc_end == len(c_tokens):\n",
        "                  break\n",
        "\n",
        "                doc_start+= self.doc_stride\n",
        "\n",
        "        # print(self.samples)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def __len__(self): return len(self.samples)\n",
        "    def __getitem__(self, idx):\n",
        "        input_ids, mask, start, end = self.samples[idx]\n",
        "        input_ids = F.pad(input_ids, (0, self.max_len - input_ids.shape[0]), value=0)\n",
        "        mask = F.pad(mask, (0, self.max_len - mask.shape[0]), value=0)\n",
        "        return {\n",
        "            \"input_ids\": input_ids,\n",
        "            \"attention_mask\": mask,\n",
        "            \"start_pos\": torch.tensor(start),\n",
        "            \"end_pos\": torch.tensor(end)\n",
        "        }\n"
      ],
      "metadata": {
        "id": "LR8E39nx0VkG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_dataset = QADataset(train_data.select(range(2000)), tokenizer)  # Use a small subset\n",
        "# train_dataset = QADataset(train_data.select(range(2000)), tokenizer)  # Use a small subset"
      ],
      "metadata": {
        "id": "7H56DW2Sd4ST"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data[2]"
      ],
      "metadata": {
        "id": "5BozEbqn3au3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(tokenizer.vocab)"
      ],
      "metadata": {
        "id": "1cO2qId6pmpX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset.__len__()"
      ],
      "metadata": {
        "id": "p3LR_zlhzLLt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "# device"
      ],
      "metadata": {
        "id": "Ci8L92BorvMk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# torch.cuda.is_available()"
      ],
      "metadata": {
        "id": "RXohBNb-sX0q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# epochs=42\n",
        "epochs = 50\n",
        "batch_size=16\n",
        "lr=5e-4"
      ],
      "metadata": {
        "id": "6enFNB3PsyVp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = QA_Transformer(vocab_size=len(tokenizer.vocab))\n"
      ],
      "metadata": {
        "id": "P7Scgbfystk4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train Model\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# initial_weights = model.embedding.weight.clone().detach() # Store initial weights\n",
        "\n",
        "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "dataset = train_dataset\n",
        "dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "# model.to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "# model.to(device) # Move model to device first\n",
        "model.train()\n",
        "\n",
        "loss_hist = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    total_loss = 0\n",
        "    for batch in dataloader:\n",
        "        input_ids = batch[\"input_ids\"]\n",
        "        mask = batch[\"attention_mask\"]\n",
        "        start_pos = batch[\"start_pos\"]\n",
        "        end_pos = batch[\"end_pos\"]\n",
        "\n",
        "        start_logits, end_logits = model(input_ids, mask)\n",
        "        loss = loss_fn(start_logits, start_pos) + loss_fn(end_logits, end_pos)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}: Loss = {total_loss / len(dataloader):.4f}\")\n",
        "    loss_hist.append(total_loss / len(dataloader))\n"
      ],
      "metadata": {
        "id": "B-E5dJf-4-cw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# updated_weights = model.embedding.weight.clone().detach()"
      ],
      "metadata": {
        "id": "2j_SbGqGP4eT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# initial_weights"
      ],
      "metadata": {
        "id": "dyjsG4pIQCi0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# updated_weights"
      ],
      "metadata": {
        "id": "E_fODqGDQCk-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(loss_hist)"
      ],
      "metadata": {
        "id": "iBtFTNOUQ-kA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# updated_weights = model.embedding.weight.clone().detach()"
      ],
      "metadata": {
        "id": "2e4TxGIZI_JJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# initial_weights"
      ],
      "metadata": {
        "id": "lRA5mf65JO9l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# updated_weights"
      ],
      "metadata": {
        "id": "ylBUqnc-JYs1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_answer(model, tokenizer, input_ids, attention_mask):\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    start_logits, end_logits = model(input_ids.unsqueeze(0), attention_mask.unsqueeze(0))\n",
        "    start = torch.argmax(start_logits, dim=1).item()\n",
        "    end = torch.argmax(end_logits, dim=1).item()\n",
        "\n",
        "    max_len = input_ids.size(0)\n",
        "    if start>end:\n",
        "      return \"\"\n",
        "    tokens = input_ids[start:end+1].tolist()\n",
        "    words = [tokenizer.reverse_vocab.get(t,'[UNK]') for t in tokens]\n",
        "    return \" \".join(words)\n"
      ],
      "metadata": {
        "id": "qg3TFTR8LIpn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Since we train with sliding window data, we should add sliding window inference\n",
        "def sliding_window_inference(question, context, tokenizer, model, max_len = 64, stride = 32):\n",
        "  input_ids, attention_mask = tokenizer.encode(question, context, max_len)\n",
        "  q_tokens = question.split()\n",
        "  c_tokens = context.split()\n",
        "  q_len = len(q_tokens)\n",
        "  c_len = len(c_tokens)\n",
        "  max_context_len = max_len - q_len - 3\n",
        "  result = []\n",
        "  doc_start = 0\n",
        "  while doc_start < c_len:\n",
        "    doc_end = min(doc_start+max_context_len, c_len)\n",
        "    new_context = ' '.join(c_tokens[doc_start:doc_end])\n",
        "    input_ids, attention_mask = tokenizer.encode(question, new_context, max_len)\n",
        "    pad_len = max_len - len(input_ids)\n",
        "    input_ids = F.pad(input_ids, (0, pad_len), value=0)\n",
        "    attention_mask = F.pad(attention_mask, (0, pad_len), value=0)\n",
        "    # input_ids = input_ids.unsqueeze(0)\n",
        "    # attention_mask = attention_mask.unsqueeze(0)\n",
        "    outputs = predict_answer(model, tokenizer, input_ids, attention_mask)\n",
        "    result.append(outputs)\n",
        "    doc_start += stride\n",
        "  return result\n",
        "\n"
      ],
      "metadata": {
        "id": "HVDLGl6AJYMt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "def normalize(text):\n",
        "  def remove_punc(s):\n",
        "    return \"\".join(c for c in s if c not in string.punctuation)\n",
        "\n",
        "  def remove_articles(s):\n",
        "    return \" \".join([w for w in s.split() if w not in [\"a\",'an','the']])\n",
        "  return remove_articles(remove_punc(text.lower())).strip()\n",
        "\n"
      ],
      "metadata": {
        "id": "k01l2IsjRpzT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_f1(pred, truth):\n",
        "  pred_tokens = normalize(pred).split()\n",
        "  truth_tokens = normalize(truth).split()\n",
        "  common = set(pred_tokens) & set(truth_tokens)\n",
        "  if len(common) == 0: return 0\n",
        "  precision = len(common) / len(pred_tokens)\n",
        "  recall = len(common) / len(truth_tokens)\n",
        "  return 2*(precision*recall) / (precision+recall)"
      ],
      "metadata": {
        "id": "8qYjajn4Synv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_em(pred,truth):\n",
        "  return int(normalize(pred) == normalize(truth))"
      ],
      "metadata": {
        "id": "jt6vHiLGVnwt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, dataset, tokenizer, num_samples=100):\n",
        "  em_scores = []\n",
        "  f1_scores = []\n",
        "  for i in range(num_samples):\n",
        "    sample = dataset.data[i]\n",
        "    question = sample['question']\n",
        "    context = sample['context']\n",
        "    gt_answer = sample['answers']['text'][0]\n",
        "    input_ids, attention_mask = tokenizer.encode(question, context, max_len = 64)\n",
        "    # input_ids = input_ids[:64]\n",
        "    # attention_mask = attention_mask[:64]\n",
        "    # pred_answer = predict_answer(model, tokenizer, input_ids, attention_mask)\n",
        "    pred_answer = sliding_window_inference(question, context, tokenizer, model, max_len = 64, stride = 32)\n",
        "    pred_answer = ' '.join(pred_answer)\n",
        "\n",
        "    em_scores.append(compute_em(pred_answer, gt_answer))\n",
        "    f1_scores.append(compute_f1(pred_answer, gt_answer))\n",
        "\n",
        "  avg_em = sum(em_scores) / len(em_scores)\n",
        "  avg_f1 = sum(f1_scores) / len(f1_scores)\n",
        "\n",
        "  print(f\"evaluate on {str(num_samples)} \\n\")\n",
        "  print(f'exact match: {avg_em:.2%}')\n",
        "  print(f'f1 score: {avg_f1:.2%}')\n",
        "  return avg_em, avg_f1"
      ],
      "metadata": {
        "id": "XVdMXz4sW2Bv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Val dataset has tokens that are not included in training dataset, hence causing errors\n",
        "## Might need to train data with both val and train\n",
        "## Or lemmentization or or better tokenization methods\n",
        "\n",
        "\n",
        "train_subset = train_data.select(range(1000))\n",
        "train_dataset = QADataset(train_subset, tokenizer)\n",
        "evaluate(model, train_dataset, tokenizer,100)"
      ],
      "metadata": {
        "id": "pYTq36DsYNPI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_subset[0]"
      ],
      "metadata": {
        "id": "VdKsdGfQRZM7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sliding_window_inference(train_subset[0]['question'], train_subset[0]['context'], tokenizer, model, max_len = 64, stride = 32)"
      ],
      "metadata": {
        "id": "Y82RG-TARdMi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids, attention_mask = tokenizer.encode(train_subset[0]['question'], train_subset[0]['context'], max_len = 64)\n",
        "input_ids = input_ids[:64]\n",
        "attention_mask = attention_mask[:64]\n",
        "pred_answer = predict_answer(model, tokenizer, input_ids, attention_mask)\n",
        "print('eval1:',pred_answer)\n",
        "pred_answer_2 = sliding_window_inference(train_subset[0]['question'], train_subset[0]['context'], tokenizer, model, max_len = 64, stride = 32)\n",
        "print('eval2:',pred_answer_2)"
      ],
      "metadata": {
        "id": "zQOVQ-G4SM6N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_subset = val_data.select(range(1000))\n",
        "val_dataset = QADataset(val_subset, tokenizer)\n",
        "evaluate(model, val_dataset, tokenizer,100)"
      ],
      "metadata": {
        "id": "XpHlZc38J53G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_data[2]"
      ],
      "metadata": {
        "id": "GfhP2tgNCtDL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_dataset.data[2]['question'], val_dataset.data[2]['answers']"
      ],
      "metadata": {
        "id": "dr67xVX_CnXp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids, attention_mask = tokenizer.encode(val_dataset.data[2]['question'], val_dataset.data[2]['context'], max_len = 64)\n",
        "input_ids = input_ids[:64]\n",
        "attention_mask = attention_mask[:64]\n",
        "pred_answer = predict_answer(model, tokenizer, input_ids, attention_mask)\n",
        "print('eval1:',pred_answer)\n",
        "pred_answer_2 = sliding_window_inference(val_dataset.data[2]['question'], val_dataset.data[2]['context'], tokenizer, model, max_len = 64, stride = 32)\n",
        "print('eval2:',pred_answer_2)"
      ],
      "metadata": {
        "id": "GOEqUG10dCRK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"What is KNN?\"\n",
        "context = '''KNN, or k-Nearest Neighbors, is a supervised machine learning algorithm used for both classification and regression tasks. It classifies new data points by finding the \"k\" most similar data points (neighbors) in the training data and assigning the new data point to the majority class among those neighbors.'''\n",
        "input_ids, attention_mask = tokenizer.encode(question, context, max_len = 64)\n",
        "# input_ids = input_ids[:64]\n",
        "# attention_mask = attention_mask[:64]\n",
        "pred_answer = predict_answer(model, tokenizer, input_ids, attention_mask)\n",
        "print('eval1:',pred_answer)\n",
        "pred_answer_2 = sliding_window_inference(question, context, tokenizer, model, max_len = 64, stride = 32)\n",
        "print('eval2:',pred_answer_2)"
      ],
      "metadata": {
        "id": "2uXLq9jedN0F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# VectorStore to store long documents / long contexts\n",
        "\n",
        "## Use KNN to retrieve documents/ contexts for questions\n",
        "\n",
        "Source: https://medium.com/@vidiptvashist/building-a-vector-database-from-scratch-in-python-6bd683ba5171\n",
        "https://sarabesh.medium.com/how-i-built-a-vector-db-with-hnsw-from-scratch-a311b6eac082\n"
      ],
      "metadata": {
        "id": "SUHDxQirv8Aa"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gKkqoWV63lr0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class knnsearch():\n",
        "  def __init__(self,k):\n",
        "    self.k = k\n",
        "\n",
        "  def cos_similarity_dist(self, vector1, vector2):\n",
        "    similarity = np.dot(vector1, vector2) / (np.linalg.norm(vector1) * np.linalg.norm(vector2))\n",
        "    return similarity\n",
        "\n",
        "  def get_neighbours(self, vector_data, query_vector):\n",
        "\n",
        "    '''\n",
        "    Get the k cloest neighbours of the query vector\n",
        "\n",
        "    input:\n",
        "      vector_data: a dictionary with query/unique id linked with its vector embedding\n",
        "      query_vector: query of interests\n",
        "\n",
        "    '''\n",
        "\n",
        "    num_neighbours = self.k\n",
        "    distances = []\n",
        "    for k,v in vector_data.items():\n",
        "      dist = self.cos_similarity_dist(query_vector, v)\n",
        "      distances.append((k,v,dist))\n",
        "\n",
        "    distances.sort(key=lambda x: x[2], reverse = True) ## Descending order here because higher cosine similairty means more similar\n",
        "    neighbours = distances[:num_neighbours]\n",
        "    return neighbours\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "leKvuo9neOkM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class VectorStore:\n",
        "  def __init__(self):\n",
        "    self.vector_data = {} ## dictionary to store vector\n",
        "\n",
        "  def add_vector(self, vector_id, vector):\n",
        "    '''\n",
        "    add a vector to the store\n",
        "    vector_id: sentence of the vector\n",
        "    vector: vector data of the sentence\n",
        "    '''\n",
        "    self.vector_data[vector_id] = vector\n",
        "\n",
        "  def get_vector(self,vector_id):\n",
        "    return self.vector_data[vector_id]\n",
        "\n",
        "\n",
        "  def knnsearch(self, query_vector, num_results = 3):\n",
        "    knn = knnsearch(num_results)\n",
        "    neighbours = knn.get_neighbours(self.vector_data, query_vector)\n",
        "    return neighbours\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "0dc21jT8eNhV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing\n",
        "\n",
        "example taken from https://medium.com/@vidiptvashist/building-a-vector-database-from-scratch-in-python-6bd683ba5171"
      ],
      "metadata": {
        "id": "_xfZ9JOWDJAR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Establish a VectorStore instance\n",
        "vector_store = VectorStore()  # Creating an instance of the VectorStore class\n",
        "\n",
        "# Define sentences\n",
        "sentences = [  # Defining a list of example sentences\n",
        "    \"I eat mango\",\n",
        "    \"mango is my favorite fruit\",\n",
        "    \"Mango is a clothing brand\",\n",
        "    \"fruits are good for health\",\n",
        "]\n",
        "\n",
        "# Tokenization and Vocabulary Creation\n",
        "vocabulary = set()  # Initializing an empty set to store unique words\n",
        "for sentence in sentences:  # Iterating over each sentence in the list\n",
        "    tokens = sentence.lower().split()  # Tokenizing the sentence by splitting on whitespace and converting to lowercase\n",
        "    vocabulary.update(tokens)  # Updating the set of vocabulary with unique tokens\n",
        "\n",
        "# Assign unique indices to vocabulary words\n",
        "word_to_index = {word: i for i, word in enumerate(vocabulary)}  # Creating a dictionary mapping words to unique indices\n",
        "\n",
        "# Vectorization\n",
        "sentence_vectors = {}  # Initializing an empty dictionary to store sentence vectors\n",
        "for sentence in sentences:  # Iterating over each sentence in the list\n",
        "    tokens = sentence.lower().split()  # Tokenizing the sentence by splitting on whitespace and converting to lowercase\n",
        "    vector = np.zeros(len(vocabulary))  # Initializing a numpy array of zeros for the sentence vector\n",
        "    for token in tokens:  # Iterating over each token in the sentence\n",
        "        vector[word_to_index[token]] += 1  # Incrementing the count of the token in the vector\n",
        "    sentence_vectors[sentence] = vector  # Storing the vector for the sentence in the dictionary\n",
        "\n",
        "# Store in VectorStore\n",
        "for sentence, vector in sentence_vectors.items():  # Iterating over each sentence vector\n",
        "    vector_store.add_vector(sentence, vector)  # Adding the sentence vector to the VectorStore\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "1hFdZyCC9xvT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vector_store.vector_data"
      ],
      "metadata": {
        "id": "JFICc5Lr-kkh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "{'I eat mango': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1.]),\n",
        " 'mango is my favorite fruit': array([1., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0.]),\n",
        " 'Mango is a clothing brand': array([0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 0., 1., 0., 0.]),\n",
        " 'fruits are good for health': array([0., 0., 1., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0.])}"
      ],
      "metadata": {
        "id": "fo3CmnqlCXkn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Similarity Search\n",
        "query_sentence = \"Mango is the best fruit\"  # Defining a query sentence\n",
        "query_vector = np.zeros(len(vocabulary))  # Initializing a numpy array of zeros for the query vector\n",
        "query_tokens = query_sentence.lower().split()  # Tokenizing the query sentence and converting to lowercase\n",
        "for token in query_tokens:  # Iterating over each token in the query sentence\n",
        "    if token in word_to_index:  # Checking if the token is present in the vocabulary\n",
        "        query_vector[word_to_index[token]] += 1  # Incrementing the count of the token in the query vector\n",
        "similar_sentences = vector_store.knnsearch(query_vector, num_results=2)  # Finding 2 similar sentences\n",
        "\n",
        "# Display similar sentences\n",
        "print(\"Query Sentence:\", query_sentence)  # Printing the query sentence\n",
        "print(\"Similar Sentences:\")  # Printing the header for similar sentences\n",
        "\n",
        "\n",
        "## Use KNN search\n",
        "for sentence, _, similarity in similar_sentences:  # Iterating over each similar sentence and its similarity score\n",
        "    print(f\"{sentence}: Similarity = {similarity:.4f}\")  # Printing the similar sentence and its similarity score"
      ],
      "metadata": {
        "id": "rPOqDZPo-nJF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Query Sentence: Mango is the best fruit <br>\n",
        "Similar Sentences: <br>\n",
        "mango is my favorite fruit: Similarity = 0.7746 <br>\n",
        "Mango is a clothing brand: Similarity = 0.5164 <br>\n",
        "\n",
        "Here we see that the order and the number of words contribute to similarity. But clearly the second sentence is not as similar to the query than the first candidate"
      ],
      "metadata": {
        "id": "8n4nluDbCZ0b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query_sentence = \"Mango is the best fruit\"  # Defining a query sentence\n",
        "query_vector = np.zeros(len(vocabulary))  # Initializing a numpy array of zeros for the query vector\n",
        "query_tokens = query_sentence.lower().split()  # Tokenizing the query sentence and converting to lowercase\n",
        "for token in query_tokens:  # Iterating over each token in the query sentence\n",
        "    if token in word_to_index:  # Checking if the token is present in the vocabulary\n",
        "        query_vector[word_to_index[token]] += 1  # Incrementing the count of the token in the query vector\n",
        "query_vector"
      ],
      "metadata": {
        "id": "3sKwJzIYGJU1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query_tokens"
      ],
      "metadata": {
        "id": "SpPhNnoGGjVp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_to_index"
      ],
      "metadata": {
        "id": "mDZykbbuGpf3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocabulary"
      ],
      "metadata": {
        "id": "IIriffqVGUb7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vector1 = np.array([0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 0., 1., 0., 0.])\n",
        "vector3 = np.array([1., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0.])\n",
        "vector4 = np.array([0., 0., 1., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0.])\n",
        "vector2 = query_vector\n",
        "print(np.dot(vector1, vector2) / (np.linalg.norm(vector1) * np.linalg.norm(vector2)))\n",
        "print(np.dot(vector3, vector2) / (np.linalg.norm(vector3) * np.linalg.norm(vector2)))\n",
        "print(np.dot(vector4, vector2) / (np.linalg.norm(vector4) * np.linalg.norm(vector2)))"
      ],
      "metadata": {
        "id": "ZCgrbRxHFqDI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.linalg.norm(vector1), np.linalg.norm(vector2),np.linalg.norm(vector3) ,np.linalg.norm(vector4)"
      ],
      "metadata": {
        "id": "pctYt3T3F4Va"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "(np.float64(2.23606797749979), <br>\n",
        " np.float64(1.7320508075688772), <br>\n",
        " np.float64(2.23606797749979), <br>\n",
        " np.float64(2.23606797749979)) <br>\n",
        "\n",
        "\n",
        "## Formula for the L2 (Euclidean) Norm of a Vector:<br>\n",
        "For a vector <br>\n",
        "\\begin{equation}\n",
        "(x=[x_{1},x_{2},...,x_{n}])\n",
        "\\end{equation},\n",
        "the L2 norm is calculated as:\n",
        "\\begin{equation}\n",
        "(\\|x\\|_{2} =\\sqrt{\\sum_{i=1}^{n}|x_{i} |^{2}})\n",
        "\\end{equation}\n",
        "This formula represents the square root of the sum of the squares of the absolute values of the vector's elements. In simpler terms, for real-valued vectors, it's the square root of the sum of the squared elements.\n",
        "\n",
        "\n",
        "## Since we are one hot encoding the sentences, sentences with the same number of word will ahve the same norm in their vectors"
      ],
      "metadata": {
        "id": "bTAFSoW5IXo7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.dot(vector1, vector2), np.dot(vector3, vector2), np.dot(vector4, vector2)"
      ],
      "metadata": {
        "id": "5SSoqZu_F-9i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## But the dot product will be different"
      ],
      "metadata": {
        "id": "YrvHtfEaJyF7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TO DO\n",
        "* Add SQuAD data into vector store\n",
        "* There are similar context in SQuAD. Can we de-dup to save space?\n",
        "* one hot encoding is not durable. Can we build use embedding?\n",
        "* Evaluate retriever\n",
        "* Add and evaluate reader"
      ],
      "metadata": {
        "id": "nOnTD8vwDzDj"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MnIXLSRr-rWC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}